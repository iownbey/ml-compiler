{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 19:39:15.203366: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-29 19:39:15.203455: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-29 19:39:15.258304: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-29 19:39:15.384168: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-29 19:39:17.012455: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "\n",
    "tf.experimental.numpy.experimental_enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Assembly</th>\n",
       "      <th>Code Digits</th>\n",
       "      <th>Operator</th>\n",
       "      <th>Mapped Operator</th>\n",
       "      <th>Assembly Digits</th>\n",
       "      <th>Assembly Templates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_1 1_+ 2_1</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>[2]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1 1_- 2_1</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_1 1_* 2_1</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>*</td>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0_1 1_+ 2_2</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>[3]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0_1 1_- 2_2</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50479</th>\n",
       "      <td>0_variable 1_- 2_98</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[98]</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>[98]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50480</th>\n",
       "      <td>0_variable 1_* 2_98</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[98]</td>\n",
       "      <td>*</td>\n",
       "      <td>2</td>\n",
       "      <td>[98]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50483</th>\n",
       "      <td>0_variable 1_+ 2_99</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[99]</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50484</th>\n",
       "      <td>0_variable 1_- 2_99</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[99]</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>[99]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50485</th>\n",
       "      <td>0_variable 1_* 2_99</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[99]</td>\n",
       "      <td>*</td>\n",
       "      <td>2</td>\n",
       "      <td>[99]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29997 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Code                                           Assembly  \\\n",
       "0              0_1 1_+ 2_1  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...   \n",
       "1              0_1 1_- 2_1  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...   \n",
       "2              0_1 1_* 2_1  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...   \n",
       "5              0_1 1_+ 2_2  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...   \n",
       "6              0_1 1_- 2_2  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...   \n",
       "...                    ...                                                ...   \n",
       "50479  0_variable 1_- 2_98  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...   \n",
       "50480  0_variable 1_* 2_98  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...   \n",
       "50483  0_variable 1_+ 2_99  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...   \n",
       "50484  0_variable 1_- 2_99  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...   \n",
       "50485  0_variable 1_* 2_99  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...   \n",
       "\n",
       "      Code Digits Operator  Mapped Operator Assembly Digits  \\\n",
       "0          [1, 1]       +                 0             [2]   \n",
       "1          [1, 1]       -                 1             [0]   \n",
       "2          [1, 1]       *                 2             [1]   \n",
       "5          [1, 2]       +                 0             [3]   \n",
       "6          [1, 2]       -                 1            [-1]   \n",
       "...           ...      ...              ...             ...   \n",
       "50479        [98]       -                 1            [98]   \n",
       "50480        [98]       *                 2            [98]   \n",
       "50483        [99]       +                 0            [99]   \n",
       "50484        [99]       -                 1            [99]   \n",
       "50485        [99]       *                 2            [99]   \n",
       "\n",
       "                                      Assembly Templates  \n",
       "0      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "1      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "2      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "5      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "6      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "...                                                  ...  \n",
       "50479  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "50480  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "50483  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "50484  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "50485  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "\n",
       "[29997 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"./1-100 plus a and b.csv\",\n",
    "    names=[\"Code\", \"Assembly\"])\n",
    "\n",
    "start_char = \"Ø\"\n",
    "end_char = \"⁂\"\n",
    "numerical_char = \"✦\"\n",
    "\n",
    "# Constrain data to constants or functions on a single variable, using the variable once\n",
    "data[\"Code\"] = data[\"Code\"].apply(lambda x: x.replace(\"int func(int a, int b)\",\"int func()\"))\n",
    "data = data[~data[\"Code\"].str.contains(r' b |b;|a . a',regex=True)]\n",
    "# Fix function headers\n",
    "data[\"Code\"] = data[\"Code\"].apply(lambda x: x.replace(\"int func()\",\"int func()\") if re.search(r' a |a;',x) else x)\n",
    "# Add spaces around punctuation\n",
    "data[\"Code\"] = data[\"Code\"].apply(lambda x: re.sub(r'([\\{\\};\\(\\)\\,])', r' \\1 ', x))\n",
    "# normalize variable name to \"variable\"\n",
    "data[\"Code\"] = data[\"Code\"].apply(lambda x: x.replace(\" a \",\" variable \"))\n",
    "# Whitelist certain operators from the training set\n",
    "data = data[data[\"Code\"].str.contains(r' \\+ | \\- | \\* ', regex=True)]\n",
    "# pull digits for training\n",
    "data[\"Code Digits\"] = data[\"Code\"].apply(lambda x: re.findall(r'\\d+', x))\n",
    "# Remove features present in every program. There is not enough data for the model to understand what these features should mean\n",
    "data[\"Code\"] = data[\"Code\"].apply(lambda x: re.sub(r' func| \\{| \\}| \\(| \\)|int| ;| return',\"\",x))\n",
    "\n",
    "# Uses heuristics to create the operator lookup table\n",
    "data[\"Operator\"] = data[\"Code\"].apply(lambda x: re.findall(r' [\\+\\-%*\\/] ',x)[0])\n",
    "# Creates the lookup table from the Code templates and the processed assembly\n",
    "operator_lookup = data[\"Operator\"].drop_duplicates().values.tolist()\n",
    "# Gets the operator index for each code sample\n",
    "data[\"Mapped Operator\"] = data[\"Operator\"].apply(lambda x: operator_lookup.index(x))\n",
    "\n",
    "# Strip the excess\n",
    "data[\"Code\"] = data[\"Code\"].apply(lambda x: x.replace(\"variable variable\",\"variable\"))\n",
    "# Adds positional data to the encodings\n",
    "def add_positiong_to_tokens(code):\n",
    "    tokens = code.split()\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = f\"{i}_{tokens[i]}\"\n",
    "    return \" \".join(tokens)\n",
    "data[\"Code\"] = data[\"Code\"].apply(lambda x: add_positiong_to_tokens(x))\n",
    "\n",
    "# Convert assembly to \"templates\" which don't contain constant numbers derived from the code.\n",
    "# This vastly reduces the number of possible outputs for a given code line.\n",
    "# The model will manually fill in the template using data from the code after it has compiled it\n",
    "r_assembly_digit = r'(?<= )[\\-]?\\d+'\n",
    "data[\"Assembly Digits\"] = data[\"Assembly\"].apply(lambda x: re.findall(r_assembly_digit, x))\n",
    "data[\"Assembly Templates\"] = data[\"Assembly\"].apply(lambda x: re.sub(r_assembly_digit, numerical_char, x)) + f\"\\n{end_char}\"\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Assembly Templates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_1 1_+ 2_1</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1 1_- 2_1</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_1 1_* 2_1</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0_1 1_+ 2_2</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0_1 1_- 2_2</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50479</th>\n",
       "      <td>0_variable 1_- 2_98</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50480</th>\n",
       "      <td>0_variable 1_* 2_98</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50483</th>\n",
       "      <td>0_variable 1_+ 2_99</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50484</th>\n",
       "      <td>0_variable 1_- 2_99</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50485</th>\n",
       "      <td>0_variable 1_* 2_99</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29997 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Code                                 Assembly Templates\n",
       "0              0_1 1_+ 2_1  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...\n",
       "1              0_1 1_- 2_1  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...\n",
       "2              0_1 1_* 2_1  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...\n",
       "5              0_1 1_+ 2_2  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...\n",
       "6              0_1 1_- 2_2  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...\n",
       "...                    ...                                                ...\n",
       "50479  0_variable 1_- 2_98  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...\n",
       "50480  0_variable 1_* 2_98  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...\n",
       "50483  0_variable 1_+ 2_99  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...\n",
       "50484  0_variable 1_- 2_99  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...\n",
       "50485  0_variable 1_* 2_99  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...\n",
       "\n",
       "[29997 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_data = pd.concat([data[\"Code\"],data[\"Assembly Templates\"]],axis=1)\n",
    "gen_data = gen_data.drop_duplicates()\n",
    "\n",
    "gen_data.reset_index(drop=True)\n",
    "\n",
    "gen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 19:40:23.680927: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-29 19:40:23.681121: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-29 19:40:23.681167: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-29 19:40:27.836414: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-29 19:40:27.836634: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-29 19:40:27.836671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-01-29 19:40:27.836812: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-29 19:40:27.836901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2739 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:3b:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "set_length = 0\n",
    "for a in gen_data[\"Assembly Templates\"]:\n",
    "    set_length += len(a.split(\"\\n\"))\n",
    "\n",
    "code_context = np.empty(shape=(set_length),dtype=object)\n",
    "gen_context = np.empty(shape=(set_length),dtype=object)\n",
    "labels = np.empty(shape=(set_length),dtype=int)\n",
    "gen_data.reset_index(drop=True)\n",
    "\n",
    "assembly_lookup = []\n",
    "\n",
    "data_i = 0\n",
    "for ri, row in gen_data.iterrows():\n",
    "    assembly = row[\"Assembly Templates\"]\n",
    "    code = row[\"Code\"]\n",
    "\n",
    "    tokenized_code = code.split()\n",
    "    tokenized = assembly.split(\"\\n\")\n",
    "\n",
    "    for ti in range(len(tokenized)):\n",
    "        if (tokenized[ti] != end_char):\n",
    "            tokenized[ti] = f\"{ti}_{tokenized[ti]}\"\n",
    "\n",
    "        t = tokenized[ti]\n",
    "\n",
    "        if (not (t in assembly_lookup)):\n",
    "            assembly_lookup += [t]\n",
    "\n",
    "        code_context[data_i] = code\n",
    "        gen_context[data_i] = \"\\n\".join(tokenized[:ti])\n",
    "        labels[data_i] = assembly_lookup.index(tokenized[ti])\n",
    "        data_i += 1\n",
    "\n",
    "gen_dataset = tf.data.Dataset.from_tensor_slices(({\"code\": code_context, \"assembly\": gen_context},labels)).batch(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(features, labels):\n",
    "  features = {\"code\": tf.strings.split(features[\"code\"]),\"assembly\": tf.strings.split(features[\"assembly\"],sep=\"\\n\")}\n",
    "  return features, labels\n",
    "\n",
    "gen_dataset = gen_dataset.map(prepare_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmp63wmb2k3 as temporary training directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 24-01-29 19:48:08.8327 EST gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-01-29 19:48:08.8327 EST gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-01-29 19:48:08.8327 EST gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Model constructor argument num_trees=90 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument num_trees=90 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training tensor examples:\n",
      "Features: {'code': tf.RaggedTensor(values=Tensor(\"data:0\", shape=(None,), dtype=string), row_splits=Tensor(\"data_1:0\", shape=(None,), dtype=int64)), 'assembly': tf.RaggedTensor(values=Tensor(\"data_2:0\", shape=(None,), dtype=string), row_splits=Tensor(\"data_3:0\", shape=(None,), dtype=int64))}\n",
      "Label: Tensor(\"data_4:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'code': SemanticTensor(semantic=<Semantic.CATEGORICAL_SET: 4>, tensor=tf.RaggedTensor(values=Tensor(\"data:0\", shape=(None,), dtype=string), row_splits=Tensor(\"data_1:0\", shape=(None,), dtype=int64))), 'assembly': SemanticTensor(semantic=<Semantic.CATEGORICAL_SET: 4>, tensor=tf.RaggedTensor(values=Tensor(\"data_2:0\", shape=(None,), dtype=string), row_splits=Tensor(\"data_3:0\", shape=(None,), dtype=int64)))}\n",
      "Training dataset read in 0:00:01.044290. Found 270757 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-29 19:48:10.2072 EST kernel.cc:771] Start Yggdrasil model training\n",
      "[INFO 24-01-29 19:48:10.2072 EST kernel.cc:772] Collect training examples\n",
      "[INFO 24-01-29 19:48:10.2072 EST kernel.cc:785] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 24-01-29 19:48:10.2073 EST kernel.cc:391] Number of batches: 271\n",
      "[INFO 24-01-29 19:48:10.2073 EST kernel.cc:392] Number of examples: 270757\n",
      "[INFO 24-01-29 19:48:10.4100 EST kernel.cc:792] Training dataset:\n",
      "Number of records: 270757\n",
      "Number of columns: 3\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL_SET: 2 (66.6667%)\n",
      "\tCATEGORICAL: 1 (33.3333%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL_SET: 2 (66.6667%)\n",
      "\t1: \"assembly\" CATEGORICAL_SET num-nas:29997 (11.0789%) has-dict vocab-size:35 zero-ood-items most-frequent:\"0_func(int, int):\" 240760 (100%)\n",
      "\t2: \"code\" CATEGORICAL_SET has-dict vocab-size:204 zero-ood-items most-frequent:\"1_*\" 90379 (33.3801%)\n",
      "\n",
      "CATEGORICAL: 1 (33.3333%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:36 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 24-01-29 19:48:10.4101 EST kernel.cc:808] Configure learner\n",
      "[WARNING 24-01-29 19:48:10.4103 EST gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-01-29 19:48:10.4103 EST gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-01-29 19:48:10.4103 EST gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 24-01-29 19:48:10.4104 EST kernel.cc:822] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^assembly$\"\n",
      "features: \"^code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  binary_focal_loss_options {\n",
      "    misprediction_exponent: 2\n",
      "    positive_sample_coefficient: 0.5\n",
      "  }\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "[INFO 24-01-29 19:48:10.4114 EST kernel.cc:825] Deployment config:\n",
      "cache_path: \"/tmp/tmp63wmb2k3/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 24-01-29 19:48:10.4119 EST kernel.cc:887] Train model\n",
      "[WARNING 24-01-29 19:48:10.4120 EST gradient_boosted_trees.cc:3146] early_stopping != \"NONE\" requires validation_set_ratio>0. Setting early_stopping=\"NONE\" (was \"VALIDATION_LOSS_INCREASE\") i.e. sabling early stopping.\n",
      "[INFO 24-01-29 19:48:10.4120 EST gradient_boosted_trees.cc:591] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[WARNING 24-01-29 19:48:10.4121 EST gradient_boosted_trees.cc:623] The model configuration specifies 300 trees but computation of the validation loss will only start at iteration 10 with 35 trees per iteration. No validation loss will be computed, early stopping is not used.\n",
      "[INFO 24-01-29 19:48:10.4121 EST gradient_boosted_trees.cc:1218] Training gradient boosted tree on 270757 example(s) and 2 feature(s).\n",
      "[INFO 24-01-29 19:48:10.4124 EST gradient_boosted_trees.cc:1261] 270757 examples used for training and 0 examples used for validation\n",
      "[INFO 24-01-29 19:48:32.2191 EST gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:2.392168 train-accuracy:0.552130\n",
      "[INFO 24-01-29 19:48:57.9069 EST gradient_boosted_trees.cc:1638] \tnum-trees:2 train-loss:1.866998 train-accuracy:0.884483\n",
      "[INFO 24-01-29 19:49:35.7885 EST gradient_boosted_trees.cc:1638] \tnum-trees:4 train-loss:1.191942 train-accuracy:0.989707\n",
      "[INFO 24-01-29 19:50:13.2403 EST gradient_boosted_trees.cc:1638] \tnum-trees:6 train-loss:0.898396 train-accuracy:0.996214\n",
      "[INFO 24-01-29 19:50:44.7600 EST gradient_boosted_trees.cc:1638] \tnum-trees:8 train-loss:0.705470 train-accuracy:0.996650\n",
      "[INFO 24-01-29 19:51:18.6499 EST gradient_boosted_trees.cc:1638] \tnum-trees:10 train-loss:0.540958 train-accuracy:0.997038\n",
      "[INFO 24-01-29 19:51:51.9505 EST gradient_boosted_trees.cc:1638] \tnum-trees:12 train-loss:0.432220 train-accuracy:0.997071\n",
      "[INFO 24-01-29 19:52:24.5713 EST gradient_boosted_trees.cc:1638] \tnum-trees:14 train-loss:0.339660 train-accuracy:0.997562\n",
      "[INFO 24-01-29 19:52:56.5095 EST gradient_boosted_trees.cc:1638] \tnum-trees:16 train-loss:0.273631 train-accuracy:0.998054\n",
      "[INFO 24-01-29 19:53:30.1993 EST gradient_boosted_trees.cc:1638] \tnum-trees:18 train-loss:0.234079 train-accuracy:0.998223\n",
      "[INFO 24-01-29 19:54:05.7759 EST gradient_boosted_trees.cc:1638] \tnum-trees:20 train-loss:0.183051 train-accuracy:0.997987\n",
      "[INFO 24-01-29 19:54:38.7238 EST gradient_boosted_trees.cc:1638] \tnum-trees:22 train-loss:0.149428 train-accuracy:0.998822\n",
      "[INFO 24-01-29 19:55:11.7589 EST gradient_boosted_trees.cc:1638] \tnum-trees:24 train-loss:0.127342 train-accuracy:0.999069\n",
      "[INFO 24-01-29 19:55:46.1673 EST gradient_boosted_trees.cc:1638] \tnum-trees:26 train-loss:0.102075 train-accuracy:0.999324\n",
      "[INFO 24-01-29 19:56:21.7085 EST gradient_boosted_trees.cc:1638] \tnum-trees:28 train-loss:0.087781 train-accuracy:0.999350\n",
      "[INFO 24-01-29 19:56:54.9621 EST gradient_boosted_trees.cc:1638] \tnum-trees:30 train-loss:0.076230 train-accuracy:0.999361\n",
      "[INFO 24-01-29 19:57:29.4530 EST gradient_boosted_trees.cc:1638] \tnum-trees:32 train-loss:0.066270 train-accuracy:0.999368\n",
      "[INFO 24-01-29 19:58:11.1959 EST gradient_boosted_trees.cc:1638] \tnum-trees:34 train-loss:0.054917 train-accuracy:0.999483\n",
      "[INFO 24-01-29 19:58:49.9126 EST gradient_boosted_trees.cc:1638] \tnum-trees:36 train-loss:0.048104 train-accuracy:0.999542\n",
      "[INFO 24-01-29 19:59:31.2519 EST gradient_boosted_trees.cc:1638] \tnum-trees:38 train-loss:0.041418 train-accuracy:0.999620\n",
      "[INFO 24-01-29 20:00:07.0335 EST gradient_boosted_trees.cc:1638] \tnum-trees:40 train-loss:0.033367 train-accuracy:0.999701\n",
      "[INFO 24-01-29 20:00:42.0883 EST gradient_boosted_trees.cc:1638] \tnum-trees:42 train-loss:0.026848 train-accuracy:0.999697\n",
      "[INFO 24-01-29 20:01:14.9412 EST gradient_boosted_trees.cc:1638] \tnum-trees:44 train-loss:0.022082 train-accuracy:0.999771\n",
      "[INFO 24-01-29 20:01:49.0736 EST gradient_boosted_trees.cc:1638] \tnum-trees:46 train-loss:0.018717 train-accuracy:0.999797\n",
      "[INFO 24-01-29 20:02:22.9878 EST gradient_boosted_trees.cc:1638] \tnum-trees:48 train-loss:0.016766 train-accuracy:0.999838\n",
      "[INFO 24-01-29 20:02:58.1633 EST gradient_boosted_trees.cc:1638] \tnum-trees:50 train-loss:0.013893 train-accuracy:0.999863\n",
      "[INFO 24-01-29 20:03:38.8964 EST gradient_boosted_trees.cc:1638] \tnum-trees:52 train-loss:0.012121 train-accuracy:0.999904\n",
      "[INFO 24-01-29 20:04:23.3820 EST gradient_boosted_trees.cc:1638] \tnum-trees:54 train-loss:0.010377 train-accuracy:0.999911\n",
      "[INFO 24-01-29 20:05:00.8766 EST gradient_boosted_trees.cc:1638] \tnum-trees:56 train-loss:0.008895 train-accuracy:0.999945\n",
      "[INFO 24-01-29 20:05:34.7434 EST gradient_boosted_trees.cc:1638] \tnum-trees:58 train-loss:0.007792 train-accuracy:0.999952\n",
      "[INFO 24-01-29 20:06:07.7130 EST gradient_boosted_trees.cc:1638] \tnum-trees:60 train-loss:0.006628 train-accuracy:0.999952\n",
      "[INFO 24-01-29 20:06:44.1776 EST gradient_boosted_trees.cc:1638] \tnum-trees:62 train-loss:0.005865 train-accuracy:0.999963\n",
      "[INFO 24-01-29 20:07:21.7974 EST gradient_boosted_trees.cc:1638] \tnum-trees:64 train-loss:0.005191 train-accuracy:0.999970\n",
      "[INFO 24-01-29 20:07:56.3962 EST gradient_boosted_trees.cc:1638] \tnum-trees:66 train-loss:0.004859 train-accuracy:0.999974\n",
      "[INFO 24-01-29 20:08:31.3686 EST gradient_boosted_trees.cc:1638] \tnum-trees:68 train-loss:0.004198 train-accuracy:0.999974\n",
      "[INFO 24-01-29 20:09:05.6128 EST gradient_boosted_trees.cc:1638] \tnum-trees:70 train-loss:0.003714 train-accuracy:0.999978\n",
      "[INFO 24-01-29 20:09:41.0759 EST gradient_boosted_trees.cc:1638] \tnum-trees:72 train-loss:0.003324 train-accuracy:0.999989\n",
      "[INFO 24-01-29 20:10:15.9455 EST gradient_boosted_trees.cc:1638] \tnum-trees:74 train-loss:0.002904 train-accuracy:0.999989\n",
      "[INFO 24-01-29 20:10:51.5440 EST gradient_boosted_trees.cc:1638] \tnum-trees:76 train-loss:0.002548 train-accuracy:0.999989\n",
      "[INFO 24-01-29 20:11:23.5111 EST gradient_boosted_trees.cc:1638] \tnum-trees:78 train-loss:0.002254 train-accuracy:0.999993\n",
      "[INFO 24-01-29 20:11:58.4647 EST gradient_boosted_trees.cc:1638] \tnum-trees:80 train-loss:0.001946 train-accuracy:0.999996\n",
      "[INFO 24-01-29 20:12:33.2297 EST gradient_boosted_trees.cc:1638] \tnum-trees:82 train-loss:0.001778 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:13:06.6052 EST gradient_boosted_trees.cc:1638] \tnum-trees:84 train-loss:0.001652 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:13:39.3244 EST gradient_boosted_trees.cc:1638] \tnum-trees:86 train-loss:0.001422 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:14:13.5807 EST gradient_boosted_trees.cc:1638] \tnum-trees:88 train-loss:0.001310 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:14:47.1084 EST gradient_boosted_trees.cc:1638] \tnum-trees:90 train-loss:0.001141 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:15:21.6989 EST gradient_boosted_trees.cc:1638] \tnum-trees:92 train-loss:0.001018 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:15:54.6480 EST gradient_boosted_trees.cc:1638] \tnum-trees:94 train-loss:0.000943 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:16:29.6282 EST gradient_boosted_trees.cc:1638] \tnum-trees:96 train-loss:0.000838 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:17:04.5136 EST gradient_boosted_trees.cc:1638] \tnum-trees:98 train-loss:0.000756 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:17:40.1509 EST gradient_boosted_trees.cc:1638] \tnum-trees:100 train-loss:0.000669 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:18:15.1041 EST gradient_boosted_trees.cc:1638] \tnum-trees:102 train-loss:0.000608 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:18:15.1041 EST gradient_boosted_trees.cc:1661] Create a snapshot of the model at iteration 101\n",
      "[INFO 24-01-29 20:18:49.5483 EST gradient_boosted_trees.cc:1638] \tnum-trees:104 train-loss:0.000537 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:19:24.4051 EST gradient_boosted_trees.cc:1638] \tnum-trees:106 train-loss:0.000483 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:19:58.9944 EST gradient_boosted_trees.cc:1638] \tnum-trees:108 train-loss:0.000427 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:20:35.5275 EST gradient_boosted_trees.cc:1638] \tnum-trees:110 train-loss:0.000386 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:21:11.4942 EST gradient_boosted_trees.cc:1638] \tnum-trees:112 train-loss:0.000354 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:21:47.3977 EST gradient_boosted_trees.cc:1638] \tnum-trees:114 train-loss:0.000313 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:22:24.0386 EST gradient_boosted_trees.cc:1638] \tnum-trees:116 train-loss:0.000279 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:23:00.2997 EST gradient_boosted_trees.cc:1638] \tnum-trees:118 train-loss:0.000251 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:23:34.8452 EST gradient_boosted_trees.cc:1638] \tnum-trees:120 train-loss:0.000229 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:24:08.7753 EST gradient_boosted_trees.cc:1638] \tnum-trees:122 train-loss:0.000209 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:24:45.1409 EST gradient_boosted_trees.cc:1638] \tnum-trees:124 train-loss:0.000191 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:25:21.3615 EST gradient_boosted_trees.cc:1638] \tnum-trees:126 train-loss:0.000169 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:25:56.8123 EST gradient_boosted_trees.cc:1638] \tnum-trees:128 train-loss:0.000154 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:26:30.9765 EST gradient_boosted_trees.cc:1638] \tnum-trees:130 train-loss:0.000138 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:27:06.0634 EST gradient_boosted_trees.cc:1638] \tnum-trees:132 train-loss:0.000126 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:27:40.2242 EST gradient_boosted_trees.cc:1638] \tnum-trees:134 train-loss:0.000115 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:28:13.8592 EST gradient_boosted_trees.cc:1638] \tnum-trees:136 train-loss:0.000109 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:28:50.2593 EST gradient_boosted_trees.cc:1638] \tnum-trees:138 train-loss:0.000103 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:29:24.3638 EST gradient_boosted_trees.cc:1638] \tnum-trees:140 train-loss:0.000091 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:29:59.4334 EST gradient_boosted_trees.cc:1638] \tnum-trees:142 train-loss:0.000082 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:30:33.7733 EST gradient_boosted_trees.cc:1638] \tnum-trees:144 train-loss:0.000076 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:31:08.4500 EST gradient_boosted_trees.cc:1638] \tnum-trees:146 train-loss:0.000068 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:31:44.4050 EST gradient_boosted_trees.cc:1638] \tnum-trees:148 train-loss:0.000063 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:32:18.5517 EST gradient_boosted_trees.cc:1638] \tnum-trees:150 train-loss:0.000058 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:32:53.8289 EST gradient_boosted_trees.cc:1638] \tnum-trees:152 train-loss:0.000053 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:33:27.3819 EST gradient_boosted_trees.cc:1638] \tnum-trees:154 train-loss:0.000048 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:34:01.5858 EST gradient_boosted_trees.cc:1638] \tnum-trees:156 train-loss:0.000044 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:34:36.8474 EST gradient_boosted_trees.cc:1638] \tnum-trees:158 train-loss:0.000041 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:35:11.0181 EST gradient_boosted_trees.cc:1638] \tnum-trees:160 train-loss:0.000038 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:35:45.5333 EST gradient_boosted_trees.cc:1638] \tnum-trees:162 train-loss:0.000035 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:36:22.6290 EST gradient_boosted_trees.cc:1638] \tnum-trees:164 train-loss:0.000033 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:37:03.1744 EST gradient_boosted_trees.cc:1638] \tnum-trees:166 train-loss:0.000030 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:37:36.4990 EST gradient_boosted_trees.cc:1638] \tnum-trees:168 train-loss:0.000027 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:38:09.1954 EST gradient_boosted_trees.cc:1638] \tnum-trees:170 train-loss:0.000025 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:38:43.5895 EST gradient_boosted_trees.cc:1638] \tnum-trees:172 train-loss:0.000023 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:39:17.4892 EST gradient_boosted_trees.cc:1638] \tnum-trees:174 train-loss:0.000021 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:39:51.4140 EST gradient_boosted_trees.cc:1638] \tnum-trees:176 train-loss:0.000020 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:40:26.4074 EST gradient_boosted_trees.cc:1638] \tnum-trees:178 train-loss:0.000019 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:41:01.3378 EST gradient_boosted_trees.cc:1638] \tnum-trees:180 train-loss:0.000017 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:41:33.7781 EST gradient_boosted_trees.cc:1638] \tnum-trees:182 train-loss:0.000016 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:42:09.8011 EST gradient_boosted_trees.cc:1638] \tnum-trees:184 train-loss:0.000014 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:42:44.3061 EST gradient_boosted_trees.cc:1638] \tnum-trees:186 train-loss:0.000013 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:43:18.6484 EST gradient_boosted_trees.cc:1638] \tnum-trees:188 train-loss:0.000012 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:43:54.3534 EST gradient_boosted_trees.cc:1638] \tnum-trees:190 train-loss:0.000011 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:44:30.5927 EST gradient_boosted_trees.cc:1638] \tnum-trees:192 train-loss:0.000010 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:45:04.1981 EST gradient_boosted_trees.cc:1638] \tnum-trees:194 train-loss:0.000010 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:45:37.2258 EST gradient_boosted_trees.cc:1638] \tnum-trees:196 train-loss:0.000009 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:46:10.2358 EST gradient_boosted_trees.cc:1638] \tnum-trees:198 train-loss:0.000008 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:46:46.7583 EST gradient_boosted_trees.cc:1638] \tnum-trees:200 train-loss:0.000008 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:47:19.8942 EST gradient_boosted_trees.cc:1638] \tnum-trees:202 train-loss:0.000007 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:47:53.7262 EST gradient_boosted_trees.cc:1638] \tnum-trees:204 train-loss:0.000007 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:48:28.5098 EST gradient_boosted_trees.cc:1638] \tnum-trees:206 train-loss:0.000006 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:48:28.5099 EST gradient_boosted_trees.cc:1661] Create a snapshot of the model at iteration 205\n",
      "[INFO 24-01-29 20:49:03.7169 EST gradient_boosted_trees.cc:1638] \tnum-trees:208 train-loss:0.000006 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:49:39.0327 EST gradient_boosted_trees.cc:1638] \tnum-trees:210 train-loss:0.000006 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:50:12.8596 EST gradient_boosted_trees.cc:1638] \tnum-trees:212 train-loss:0.000005 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:50:47.8656 EST gradient_boosted_trees.cc:1638] \tnum-trees:214 train-loss:0.000005 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:51:22.1891 EST gradient_boosted_trees.cc:1638] \tnum-trees:216 train-loss:0.000005 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:51:57.6575 EST gradient_boosted_trees.cc:1638] \tnum-trees:218 train-loss:0.000004 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:52:31.6886 EST gradient_boosted_trees.cc:1638] \tnum-trees:220 train-loss:0.000004 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:53:06.4742 EST gradient_boosted_trees.cc:1638] \tnum-trees:222 train-loss:0.000004 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:53:39.5045 EST gradient_boosted_trees.cc:1638] \tnum-trees:224 train-loss:0.000003 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:54:14.0516 EST gradient_boosted_trees.cc:1638] \tnum-trees:226 train-loss:0.000003 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:54:47.9326 EST gradient_boosted_trees.cc:1638] \tnum-trees:228 train-loss:0.000003 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:55:24.6443 EST gradient_boosted_trees.cc:1638] \tnum-trees:230 train-loss:0.000003 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:55:58.7973 EST gradient_boosted_trees.cc:1638] \tnum-trees:232 train-loss:0.000003 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:56:32.8304 EST gradient_boosted_trees.cc:1638] \tnum-trees:234 train-loss:0.000002 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:57:07.1771 EST gradient_boosted_trees.cc:1638] \tnum-trees:236 train-loss:0.000002 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:57:42.2254 EST gradient_boosted_trees.cc:1638] \tnum-trees:238 train-loss:0.000002 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:58:16.6046 EST gradient_boosted_trees.cc:1638] \tnum-trees:240 train-loss:0.000002 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:58:51.5584 EST gradient_boosted_trees.cc:1638] \tnum-trees:242 train-loss:0.000002 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:59:24.9412 EST gradient_boosted_trees.cc:1638] \tnum-trees:244 train-loss:0.000002 train-accuracy:1.000000\n",
      "[INFO 24-01-29 20:59:57.5058 EST gradient_boosted_trees.cc:1638] \tnum-trees:246 train-loss:0.000002 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:00:29.6072 EST gradient_boosted_trees.cc:1638] \tnum-trees:248 train-loss:0.000002 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:01:02.6606 EST gradient_boosted_trees.cc:1638] \tnum-trees:250 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:01:37.7592 EST gradient_boosted_trees.cc:1638] \tnum-trees:252 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:02:12.0007 EST gradient_boosted_trees.cc:1638] \tnum-trees:254 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:02:46.4206 EST gradient_boosted_trees.cc:1638] \tnum-trees:256 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:03:22.1926 EST gradient_boosted_trees.cc:1638] \tnum-trees:258 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:03:58.0785 EST gradient_boosted_trees.cc:1638] \tnum-trees:260 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:04:34.7604 EST gradient_boosted_trees.cc:1638] \tnum-trees:262 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:05:07.9287 EST gradient_boosted_trees.cc:1638] \tnum-trees:264 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:05:41.9045 EST gradient_boosted_trees.cc:1638] \tnum-trees:266 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:06:16.0039 EST gradient_boosted_trees.cc:1638] \tnum-trees:268 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:06:49.0500 EST gradient_boosted_trees.cc:1638] \tnum-trees:270 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:07:23.0833 EST gradient_boosted_trees.cc:1638] \tnum-trees:272 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:07:58.2788 EST gradient_boosted_trees.cc:1638] \tnum-trees:274 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:08:32.1951 EST gradient_boosted_trees.cc:1638] \tnum-trees:276 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:09:05.0878 EST gradient_boosted_trees.cc:1638] \tnum-trees:278 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:09:41.4471 EST gradient_boosted_trees.cc:1638] \tnum-trees:280 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:10:22.3520 EST gradient_boosted_trees.cc:1638] \tnum-trees:282 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:10:55.4197 EST gradient_boosted_trees.cc:1638] \tnum-trees:284 train-loss:0.000001 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:11:29.8002 EST gradient_boosted_trees.cc:1638] \tnum-trees:286 train-loss:0.000000 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:12:03.4727 EST gradient_boosted_trees.cc:1638] \tnum-trees:288 train-loss:0.000000 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:12:36.5125 EST gradient_boosted_trees.cc:1638] \tnum-trees:290 train-loss:0.000000 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:13:10.4065 EST gradient_boosted_trees.cc:1638] \tnum-trees:292 train-loss:0.000000 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:13:44.2155 EST gradient_boosted_trees.cc:1638] \tnum-trees:294 train-loss:0.000000 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:14:18.8891 EST gradient_boosted_trees.cc:1638] \tnum-trees:296 train-loss:0.000000 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:14:53.1030 EST gradient_boosted_trees.cc:1638] \tnum-trees:298 train-loss:0.000000 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:15:25.9648 EST gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.000000 train-accuracy:1.000000\n",
      "[INFO 24-01-29 21:15:25.9648 EST gradient_boosted_trees.cc:1675] Create final snapshot of the model at iteration 300\n",
      "[INFO 24-01-29 21:15:26.4075 EST kernel.cc:919] Export model in log directory: /tmp/tmp63wmb2k3 with prefix ea6c2094bf3c4b2e\n",
      "[INFO 24-01-29 21:15:26.7915 EST kernel.cc:937] Save model in resources\n",
      "[WARNING 24-01-29 21:15:26.7999 EST gradient_boosted_trees.cc:514] Validation evaluation not available for the Gradient Boosted Tree model as no validation dataset was provided for training (i.e. validation_set_ratio == 0).\n",
      "[INFO 24-01-29 21:15:27.0697 EST kernel.cc:1233] Loading model from path /tmp/tmp63wmb2k3/model/ with prefix ea6c2094bf3c4b2e\n",
      "[INFO 24-01-29 21:15:28.5500 EST decision_forest.cc:660] Model loaded with 10500 root(s), 508758 node(s), and 2 input feature(s).\n",
      "[INFO 24-01-29 21:15:28.5501 EST abstract_model.cc:1344] Engine \"GradientBoostedTreesGeneric\" built\n",
      "[INFO 24-01-29 21:15:28.5501 EST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 1:27:18.539697\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f27424f6560>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tuner = tfdf.tuner.RandomSearch(num_trials=50, use_predefined_hps=True)\n",
    "# We want to overfit, since this is a compilation problem and we are training on all the inputs.\n",
    "gen_model = tfdf.keras.GradientBoostedTreesModel(validation_ratio=0.0)\n",
    "gen_model.fit(gen_dataset, num_trees = 90, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_line(code, context = \"\"):\n",
    "    return np.argmax(gen_model({\"code\":tf.strings.split([code]), \"assembly\":tf.strings.split([context],sep=\"\\n\")})[0])\n",
    "\n",
    "def generate_template(code, sanity=50):\n",
    "    code = re.sub(r'([\\{\\};\\(\\)\\,])', r' \\1 ', code)\n",
    "    interim = \"\"\n",
    "    while not interim.endswith(end_char + \"\\n\") and sanity > 0:\n",
    "        interim += assembly_lookup[generate_line(code,interim)] + \"\\n\"\n",
    "        sanity -= 1\n",
    "    return interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_save_dataset(percentage = 1):\n",
    "    sampled_data = data[::round(1/percentage)]\n",
    "    time_str = datetime.now().strftime('%m-%d-%Y--%H-%M-%S')\n",
    "    file_loc = f\"datasets/{time_str}.pkl\"\n",
    "    sampled_data.to_pickle(file_loc)\n",
    "    print(f\"Saved to '{file_loc}'\")\n",
    "    return sampled_data\n",
    "\n",
    "def load_dataset(location):\n",
    "    return pd.read_pickle(location)\n",
    "\n",
    "# sampled_data = sample_and_save_dataset(0.5)\n",
    "\n",
    "# train/validation = 80%, test = 20%\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 8 thread(s) for training\n",
      "Use /tmp/tmp1uxwmslg as temporary training directory\n",
      "Reading training dataset...\n",
      "Training tensor examples:\n",
      "Features: {'features': tf.RaggedTensor(values=Tensor(\"data:0\", shape=(None,), dtype=string), row_splits=Tensor(\"data_1:0\", shape=(None,), dtype=int64))}\n",
      "Label: Tensor(\"data_2:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'features': SemanticTensor(semantic=<Semantic.CATEGORICAL_SET: 4>, tensor=tf.RaggedTensor(values=Tensor(\"data:0\", shape=(None,), dtype=string), row_splits=Tensor(\"data_1:0\", shape=(None,), dtype=int64)))}\n",
      "Training dataset read in 0:00:00.787228. Found 29997 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-30 14:23:31.5866 EST kernel.cc:771] Start Yggdrasil model training\n",
      "[INFO 24-01-30 14:23:31.5889 EST kernel.cc:772] Collect training examples\n",
      "[INFO 24-01-30 14:23:31.5896 EST kernel.cc:785] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 24-01-30 14:23:31.5975 EST kernel.cc:391] Number of batches: 30\n",
      "[INFO 24-01-30 14:23:31.5975 EST kernel.cc:392] Number of examples: 29997\n",
      "[INFO 24-01-30 14:23:31.6127 EST kernel.cc:792] Training dataset:\n",
      "Number of records: 29997\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL_SET: 1 (50%)\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL_SET: 1 (50%)\n",
      "\t1: \"features\" CATEGORICAL_SET has-dict vocab-size:204 zero-ood-items most-frequent:\"1_*\" 9999 (33.3333%)\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 24-01-30 14:23:31.6135 EST kernel.cc:808] Configure learner\n",
      "[INFO 24-01-30 14:23:31.6136 EST kernel.cc:822] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^features$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 50\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "[INFO 24-01-30 14:23:31.6156 EST kernel.cc:825] Deployment config:\n",
      "cache_path: \"/tmp/tmp1uxwmslg/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 24-01-30 14:23:31.6169 EST kernel.cc:887] Train model\n",
      "[INFO 24-01-30 14:23:31.6181 EST random_forest.cc:416] Training random forest on 29997 example(s) and 1 feature(s).\n",
      "[INFO 24-01-30 14:23:31.7328 EST random_forest.cc:802] Training of tree  1/50 (tree index:5) done accuracy:0.996924 logloss:0.110883\n",
      "[INFO 24-01-30 14:23:32.0530 EST random_forest.cc:802] Training of tree  11/50 (tree index:16) done accuracy:0.995539 logloss:0.0667954\n",
      "[INFO 24-01-30 14:23:32.2713 EST random_forest.cc:802] Training of tree  21/50 (tree index:22) done accuracy:0.9991 logloss:0.0784159\n",
      "[INFO 24-01-30 14:23:32.4748 EST random_forest.cc:802] Training of tree  31/50 (tree index:27) done accuracy:0.999867 logloss:0.0861781\n",
      "[INFO 24-01-30 14:23:32.6231 EST random_forest.cc:802] Training of tree  41/50 (tree index:35) done accuracy:0.999967 logloss:0.0788362\n",
      "[INFO 24-01-30 14:23:32.7787 EST random_forest.cc:802] Training of tree  50/50 (tree index:48) done accuracy:1 logloss:0.0756706\n",
      "[INFO 24-01-30 14:23:32.7788 EST random_forest.cc:882] Final OOB metrics: accuracy:1 logloss:0.0756706\n",
      "[INFO 24-01-30 14:23:32.7805 EST kernel.cc:919] Export model in log directory: /tmp/tmp1uxwmslg with prefix cf2fe0ef70cf4124\n",
      "[INFO 24-01-30 14:23:32.7929 EST kernel.cc:937] Save model in resources\n",
      "[INFO 24-01-30 14:23:32.7985 EST abstract_model.cc:881] Model self evaluation:\n",
      "Number of predictions (without weights): 29997\n",
      "Number of predictions (with weights): 29997\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 1  CI95[W][0.9999 1]\n",
      "LogLoss: : 0.0756706\n",
      "ErrorRate: : 0\n",
      "\n",
      "Default Accuracy: : 0.333333\n",
      "Default LogLoss: : 1.09861\n",
      "Default ErrorRate: : 0.666667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "      1     2     3\n",
      "1  9999     0     0\n",
      "2     0  9999     0\n",
      "3     0     0  9999\n",
      "Total: 29997\n",
      "\n",
      "\n",
      "[INFO 24-01-30 14:23:32.8294 EST kernel.cc:1233] Loading model from path /tmp/tmp1uxwmslg/model/ with prefix cf2fe0ef70cf4124\n",
      "[INFO 24-01-30 14:23:32.8730 EST decision_forest.cc:660] Model loaded with 50 root(s), 7144 node(s), and 1 input feature(s).\n",
      "[INFO 24-01-30 14:23:32.8731 EST abstract_model.cc:1344] Engine \"RandomForestGeneric\" built\n",
      "[INFO 24-01-30 14:23:32.8734 EST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:01.318909\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    }
   ],
   "source": [
    "#x_input = tf.keras.Input(shape=(1,),dtype=tf.string)\n",
    "#x = code_vectorizer(x_input)\n",
    "#x = tf.keras.layers.Embedding(label_length,class_count)(x)\n",
    "#x = tf.keras.layers.GRU(class_count)(x)\n",
    "#x = tf.keras.layers.Dense(class_count, activation='softmax')(x)\n",
    "\n",
    "#model = tf.keras.Model(inputs=x_input,outputs=x)\n",
    "\n",
    "pf = pd.concat([data[\"Code\"],data[\"Mapped Operator\"]],axis=1)\n",
    "pf = pf.rename(columns={\"Code\": \"features\", \"Mapped Operator\": \"labels\"})\n",
    "tf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(pf, label=\"labels\")\n",
    "\n",
    "def prepare_dataset(features, labels):\n",
    "  features = {\"features\": tf.strings.split(features[\"features\"])}\n",
    "  return features, labels\n",
    "\n",
    "tf_dataset = tf_dataset.map(prepare_dataset)\n",
    "\n",
    "op_model = tfdf.keras.RandomForestModel(num_trees=50,verbose=2)\n",
    "op_history = op_model.fit(tf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_operator(code):\n",
    "    return np.argmax(op_model.call({\"features\": tf.strings.split([code])})[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5001/837620651.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  relevant_data[\"Code Digits\"] = relevant_data[\"Code Digits\"].apply(lambda x: x + ([0] * (3-len(x))))\n",
      "/tmp/ipykernel_5001/837620651.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  relevant_data[\"Assembly Digits\"] = relevant_data[\"Assembly Digits\"].apply(lambda x: x + ([0] * (3-len(x))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 4s 9ms/step - loss: 31.1827 - val_loss: 4.0765e-04\n",
      "Epoch 2/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 3.1143e-04 - val_loss: 2.2176e-04\n",
      "Epoch 3/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 1.4474e-04 - val_loss: 1.3440e-04\n",
      "Epoch 4/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 5.8821e-05 - val_loss: 1.4226e-05\n",
      "Epoch 5/100\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 0.0826 - val_loss: 0.0360\n",
      "Epoch 6/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.0404 - val_loss: 1.6038e-04\n",
      "Epoch 7/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.4395 - val_loss: 0.3122\n",
      "Epoch 8/100\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 0.0827 - val_loss: 4.4427e-05\n",
      "Epoch 9/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 7.2544e-06 - val_loss: 1.4641e-06\n",
      "Epoch 10/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 5.0504e-07 - val_loss: 2.5591e-07\n",
      "Epoch 11/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 7.5381e-07 - val_loss: 1.0828e-07\n",
      "Epoch 12/100\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 0.2084 - val_loss: 2.0547\n",
      "Epoch 13/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.6874 - val_loss: 4.0353e-05\n",
      "Epoch 14/100\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 1.1426e-05 - val_loss: 2.4532e-06\n",
      "Epoch 15/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 1.1544e-06 - val_loss: 3.3611e-06\n",
      "Epoch 16/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.2599 - val_loss: 17.9092\n",
      "Epoch 17/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.6034 - val_loss: 3.6740e-05\n",
      "Epoch 18/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 4.8957e-05 - val_loss: 8.8117e-07\n",
      "Epoch 19/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 1.3929e-07 - val_loss: 1.9668e-07\n",
      "Epoch 20/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.3248 - val_loss: 0.0320\n",
      "Epoch 21/100\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 4.1630e-04 - val_loss: 8.4577e-06\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5001/837620651.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  relevant_data[\"Code Digits\"] = relevant_data[\"Code Digits\"].apply(lambda x: x + ([0] * (3-len(x))))\n",
      "/tmp/ipykernel_5001/837620651.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  relevant_data[\"Assembly Digits\"] = relevant_data[\"Assembly Digits\"].apply(lambda x: x + ([0] * (3-len(x))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 4s 9ms/step - loss: 6.7117 - val_loss: 1.2680e-06\n",
      "Epoch 2/100\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 0.0591 - val_loss: 2.3030\n",
      "Epoch 3/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.1008 - val_loss: 0.0089\n",
      "Epoch 4/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 8.0821e-04 - val_loss: 6.5993e-05\n",
      "Epoch 5/100\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 0.0972 - val_loss: 0.0096\n",
      "Epoch 6/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.1031 - val_loss: 0.6500\n",
      "Epoch 7/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.0319 - val_loss: 0.0062\n",
      "Epoch 8/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.1094 - val_loss: 0.0044\n",
      "Epoch 9/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.2004 - val_loss: 0.0652\n",
      "Epoch 10/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 11/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5001/837620651.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  relevant_data[\"Code Digits\"] = relevant_data[\"Code Digits\"].apply(lambda x: x + ([0] * (3-len(x))))\n",
      "/tmp/ipykernel_5001/837620651.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  relevant_data[\"Assembly Digits\"] = relevant_data[\"Assembly Digits\"].apply(lambda x: x + ([0] * (3-len(x))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 4s 9ms/step - loss: 517566.4062 - val_loss: 1426187.0000\n",
      "Epoch 2/100\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 399622.1250 - val_loss: 1182860.5000\n",
      "Epoch 3/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 261432.0938 - val_loss: 810383.6250\n",
      "Epoch 4/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 208983.3125 - val_loss: 755975.8125\n",
      "Epoch 5/100\n",
      "282/282 [==============================] - 4s 13ms/step - loss: 201403.9219 - val_loss: 745365.1250\n",
      "Epoch 6/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 198521.7188 - val_loss: 702676.6250\n",
      "Epoch 7/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 196258.9688 - val_loss: 777885.1250\n",
      "Epoch 8/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 198721.8438 - val_loss: 554198.8125\n",
      "Epoch 9/100\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 196918.8125 - val_loss: 791973.1250\n",
      "Epoch 10/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 197891.5312 - val_loss: 572176.5625\n",
      "Epoch 11/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 199271.1875 - val_loss: 754694.8125\n",
      "Epoch 12/100\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 197536.3125 - val_loss: 700269.6250\n",
      "Epoch 13/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 198399.7812 - val_loss: 718081.5625\n",
      "Epoch 14/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 200979.6094 - val_loss: 733433.1875\n",
      "Epoch 15/100\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 202183.6250 - val_loss: 752783.8125\n",
      "Epoch 16/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 195573.1250 - val_loss: 810892.1875\n",
      "Epoch 17/100\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 197164.4688 - val_loss: 587082.0625\n",
      "Epoch 18/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 197205.8281 - val_loss: 888730.5625\n"
     ]
    }
   ],
   "source": [
    "### OPTIMIZATION ###\n",
    "\n",
    "### Here, it generates a model per operator. These train off the data as well\n",
    "### This number is data dependent\n",
    "\n",
    "operator_models = [None] * len(operator_lookup)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "for ri in range(len(operator_lookup)):\n",
    "\n",
    "    operator_models[ri] = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(256),\n",
    "        tf.keras.layers.Dense(256),\n",
    "        tf.keras.layers.Dense(256),\n",
    "        tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "    operator_models[ri].compile(loss=\"mse\",optimizer=\"adam\")\n",
    "\n",
    "    relevant_data = data[data[\"Mapped Operator\"] == ri]\n",
    "\n",
    "    relevant_data[\"Code Digits\"] = relevant_data[\"Code Digits\"].apply(lambda x: x + ([0] * (3-len(x))))\n",
    "    relevant_data[\"Assembly Digits\"] = relevant_data[\"Assembly Digits\"].apply(lambda x: x + ([0] * (3-len(x))))\n",
    "\n",
    "    inputs = np.stack(relevant_data[\"Code Digits\"].to_numpy()).astype(int)\n",
    "    outputs = np.stack(relevant_data[\"Assembly Digits\"].to_numpy()).astype(int)\n",
    "\n",
    "    operator_models[ri].fit(x=inputs, y=outputs, validation_split=0.1, epochs=100, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_numbers(code_numbers, operator):\n",
    "    output = operator_models[operator](np.array([code_numbers]).astype(int))[0][0]\n",
    "    return round(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splice_numbers_into_assembly(template,digit):\n",
    "    return template.replace(numerical_char,str(digit.numpy().astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefixes(template):\n",
    "    lines = template.split('\\n')\n",
    "    lines = [(line.split('_')[1] if (\"_\" in line) else line) for line in lines]\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_code(code):\n",
    "    digits = re.findall(r'\\d+', code)\n",
    "    digits = digits + ([0] * (3 - len(digits)))\n",
    "\n",
    "    tokens = code.split()\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = f\"{i}_{tokens[i]}\"\n",
    "    code = \" \".join(tokens)\n",
    "\n",
    "    operator_n = classify_operator(code)\n",
    "    final_digit = compile_numbers(digits,operator_n)\n",
    "    assembly_template = generate_template(code)\n",
    "    spliced_assembly = splice_numbers_into_assembly(assembly_template, final_digit)\n",
    "    return remove_prefixes(spliced_assembly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "push rbp\n",
      "mov rbp, rsp\n",
      "mov DWORD PTR [rbp-4], edi\n",
      "mov DWORD PTR [rbp-8], esi\n",
      "mov eax, 384\n",
      "pop rbp\n",
      "ret\n",
      "⁂\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(compile_code(\"384\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
