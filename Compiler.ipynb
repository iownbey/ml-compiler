{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 20:14:54.431820: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-03 20:14:54.432027: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-03 20:14:54.460810: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-03 20:14:54.539670: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-03 20:14:56.142340: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import re\n",
    "\n",
    "tf.experimental.numpy.experimental_enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Assembly</th>\n",
       "      <th>Code Digits</th>\n",
       "      <th>Operator</th>\n",
       "      <th>Mapped Operator</th>\n",
       "      <th>Assembly Digits</th>\n",
       "      <th>Assembly Templates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_1 1_+ 2_1</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>[2]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1 1_- 2_1</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_1 1_* 2_1</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>*</td>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0_1 1_+ 2_2</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>[3]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0_1 1_- 2_2</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50484</th>\n",
       "      <td>0_variable_a 1_- 2_99</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[99]</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>[99]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50485</th>\n",
       "      <td>0_variable_a 1_* 2_99</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[99]</td>\n",
       "      <td>*</td>\n",
       "      <td>2</td>\n",
       "      <td>[99]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50488</th>\n",
       "      <td>0_variable_a 1_+ 2_variable_a</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[]</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50489</th>\n",
       "      <td>0_variable_a 1_- 2_variable_a</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[]</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50490</th>\n",
       "      <td>0_variable_a 1_* 2_variable_a</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "      <td>[]</td>\n",
       "      <td>*</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Code  \\\n",
       "0                        0_1 1_+ 2_1   \n",
       "1                        0_1 1_- 2_1   \n",
       "2                        0_1 1_* 2_1   \n",
       "5                        0_1 1_+ 2_2   \n",
       "6                        0_1 1_- 2_2   \n",
       "...                              ...   \n",
       "50484          0_variable_a 1_- 2_99   \n",
       "50485          0_variable_a 1_* 2_99   \n",
       "50488  0_variable_a 1_+ 2_variable_a   \n",
       "50489  0_variable_a 1_- 2_variable_a   \n",
       "50490  0_variable_a 1_* 2_variable_a   \n",
       "\n",
       "                                                Assembly Code Digits Operator  \\\n",
       "0      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...      [1, 1]       +    \n",
       "1      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...      [1, 1]       -    \n",
       "2      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...      [1, 1]       *    \n",
       "5      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...      [1, 2]       +    \n",
       "6      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...      [1, 2]       -    \n",
       "...                                                  ...         ...      ...   \n",
       "50484  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...        [99]       -    \n",
       "50485  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...        [99]       *    \n",
       "50488  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...          []       +    \n",
       "50489  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...          []       -    \n",
       "50490  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...          []       *    \n",
       "\n",
       "       Mapped Operator Assembly Digits  \\\n",
       "0                    0             [2]   \n",
       "1                    1             [0]   \n",
       "2                    2             [1]   \n",
       "5                    0             [3]   \n",
       "6                    1            [-1]   \n",
       "...                ...             ...   \n",
       "50484                1            [99]   \n",
       "50485                2            [99]   \n",
       "50488                0              []   \n",
       "50489                1             [0]   \n",
       "50490                2              []   \n",
       "\n",
       "                                      Assembly Templates  \n",
       "0      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "1      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "2      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "5      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "6      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "...                                                  ...  \n",
       "50484  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "50485  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "50488  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "50489  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "50490  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "\n",
       "[30000 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"./1-99 plus a and b.csv\",\n",
    "    names=[\"Code\", \"Assembly\"])\n",
    "\n",
    "start_char = \"Ø\"\n",
    "end_char = \"⁂\"\n",
    "numerical_char = \"✦\"\n",
    "\n",
    "# Constrain data to constants or functions on a single variable, using the variable once\n",
    "data[\"Code\"] = data[\"Code\"].apply(lambda x: x.replace(\"int func(int a, int b)\",\"int func()\"))\n",
    "# Fix function headers\n",
    "data[\"Code\"] = data[\"Code\"].apply(lambda x: x.replace(\"int func()\",\"int func()\") if re.search(r' a |a;',x) else x)\n",
    "# Add spaces around punctuation\n",
    "data[\"Code\"] = data[\"Code\"].apply(lambda x: re.sub(r'([\\{\\};\\(\\)\\,])', r' \\1 ', x))\n",
    "# normalize variable name to \"variable\"\n",
    "data[\"Code\"] = data[\"Code\"].apply(lambda x: x.replace(\" a \",\" variable_a \"))\n",
    "data = data[~data[\"Code\"].str.contains(\" b \")]\n",
    "#data[\"Code\"] = data[\"Code\"].apply(lambda x: x.replace(\" b \",\" variable_b \"))\n",
    "# Whitelist certain operators from the training set\n",
    "data = data[data[\"Code\"].str.contains(r' \\+ | \\- | \\* ', regex=True)]\n",
    "# pull digits for training\n",
    "data[\"Code Digits\"] = data[\"Code\"].apply(lambda x: re.findall(r'\\d+', x))\n",
    "# Remove features present in every program. There is not enough data for the model to understand what these features should mean\n",
    "data[\"Code\"] = data[\"Code\"].apply(lambda x: re.sub(r' func| \\{| \\}| \\(| \\)|int| ;| return',\"\",x))\n",
    "\n",
    "# Uses heuristics to create the operator lookup table\n",
    "data[\"Operator\"] = data[\"Code\"].apply(lambda x: re.findall(r' [\\+\\-%*\\/] ',x)[0])\n",
    "# Creates the lookup table from the Code templates and the processed assembly\n",
    "operator_lookup = data[\"Operator\"].drop_duplicates().values.tolist()\n",
    "# Gets the operator index for each code sample\n",
    "data[\"Mapped Operator\"] = data[\"Operator\"].apply(lambda x: operator_lookup.index(x))\n",
    "\n",
    "# Strip the excess\n",
    "data[\"Code\"] = data[\"Code\"].apply(lambda x: x.replace(\"variable variable\",\"variable\"))\n",
    "# Adds positional data to the encodings\n",
    "def add_positioning_to_tokens(code):\n",
    "    tokens = code.split()\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = f\"{i}_{tokens[i]}\"\n",
    "    return \" \".join(tokens)\n",
    "data[\"Code\"] = data[\"Code\"].apply(lambda x: add_positioning_to_tokens(x))\n",
    "\n",
    "# Convert assembly to \"templates\" which don't contain constant numbers derived from the code.\n",
    "# This vastly reduces the number of possible outputs for a given code line.\n",
    "# The model will manually fill in the template using data from the code after it has compiled it\n",
    "r_assembly_digit = r'(?<= )[\\-]?\\d+'\n",
    "data[\"Assembly Digits\"] = data[\"Assembly\"].apply(lambda x: re.findall(r_assembly_digit, x))\n",
    "data[\"Assembly Templates\"] = data[\"Assembly\"].apply(lambda x: re.sub(r_assembly_digit, numerical_char, x)) + f\"\\n{end_char}\"\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Assembly Templates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_1 1_+ 2_1</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1 1_- 2_1</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_1 1_* 2_1</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_1 1_+ 2_2</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_1 1_- 2_2</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0_variable_a 1_- 2_99</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0_variable_a 1_* 2_99</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0_variable_a 1_+ 2_variable_a</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0_variable_a 1_- 2_variable_a</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0_variable_a 1_* 2_variable_a</td>\n",
       "      <td>func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Code  \\\n",
       "0                        0_1 1_+ 2_1   \n",
       "1                        0_1 1_- 2_1   \n",
       "2                        0_1 1_* 2_1   \n",
       "3                        0_1 1_+ 2_2   \n",
       "4                        0_1 1_- 2_2   \n",
       "...                              ...   \n",
       "29995          0_variable_a 1_- 2_99   \n",
       "29996          0_variable_a 1_* 2_99   \n",
       "29997  0_variable_a 1_+ 2_variable_a   \n",
       "29998  0_variable_a 1_- 2_variable_a   \n",
       "29999  0_variable_a 1_* 2_variable_a   \n",
       "\n",
       "                                      Assembly Templates  \n",
       "0      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "1      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "2      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "3      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "4      func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "...                                                  ...  \n",
       "29995  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "29996  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "29997  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "29998  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "29999  func(int, int):\\npush rbp\\nmov rbp, rsp\\nmov D...  \n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_data = pd.concat([data[\"Code\"],data[\"Assembly Templates\"]],axis=1)\n",
    "gen_data = gen_data.drop_duplicates()\n",
    "gen_data = gen_data.reset_index(drop=True)\n",
    "\n",
    "gen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': {'count': 30000, 'index': 0}, '0_func(int, int):': {'count': 240786, 'index': 1}, '1_push rbp': {'count': 210786, 'index': 2}, '2_mov rbp, rsp': {'count': 180786, 'index': 3}, '3_mov DWORD PTR [rbp-4], edi': {'count': 150786, 'index': 4}, '4_mov DWORD PTR [rbp-8], esi': {'count': 120786, 'index': 5}, '5_mov eax, ✦': {'count': 88608, 'index': 6}, '6_pop rbp': {'count': 58812, 'index': 7}, '7_ret': {'count': 29406, 'index': 8}, '5_mov eax, DWORD PTR [rbp-4]': {'count': 1730, 'index': 2679}, '6_add eax, ✦': {'count': 594, 'index': 2680}, '7_pop rbp': {'count': 1060, 'index': 2681}, '8_ret': {'count': 530, 'index': 2682}, '6_sub eax, DWORD PTR [rbp-4]': {'count': 297, 'index': 2690}, '6_add eax, eax': {'count': 9, 'index': 5402}, '5_mov edx, DWORD PTR [rbp-4]': {'count': 448, 'index': 8104}, '6_mov eax, edx': {'count': 384, 'index': 8105}, '7_add eax, eax': {'count': 82, 'index': 8106}, '8_add eax, edx': {'count': 232, 'index': 8107}, '9_pop rbp': {'count': 40, 'index': 8108}, '10_ret': {'count': 20, 'index': 8109}, '6_sal eax, ✦': {'count': 30, 'index': 10810}, '7_sal eax, ✦': {'count': 238, 'index': 13514}, '9_add eax, eax': {'count': 34, 'index': 16221}, '10_pop rbp': {'count': 48, 'index': 16222}, '11_ret': {'count': 24, 'index': 16223}, '8_sub eax, edx': {'count': 24, 'index': 18926}, '10_add eax, edx': {'count': 60, 'index': 29747}, '11_pop rbp': {'count': 40, 'index': 29748}, '12_ret': {'count': 20, 'index': 29749}, '9_sal eax, ✦': {'count': 94, 'index': 32453}, '6_imul eax, eax, ✦': {'count': 360, 'index': 37863}, '9_lea edx, [0+rax*4]': {'count': 8, 'index': 67620}, '9_lea edx, [0+rax*8]': {'count': 16, 'index': 73030}, '6_sub eax, ✦': {'count': 297, 'index': 267709}, '6_imul eax, eax': {'count': 3, 'index': 270783}}\n",
      "Warning: 6_imul eax, eax only has 3 instances; duplicating so it is not considered OoV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 20:15:18.925853: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-03 20:15:19.326342: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-03 20:15:19.326409: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-03 20:15:19.330168: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-03 20:15:19.330296: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-03 20:15:19.330412: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-03 20:15:20.143478: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-03 20:15:20.143605: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-03 20:15:20.143620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-03 20:15:20.143671: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-03 20:15:20.143779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2865 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:3b:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "set_length = 0\n",
    "for a in gen_data[\"Assembly Templates\"]:\n",
    "    set_length += len(a.split(\"\\n\"))\n",
    "\n",
    "code_context = np.empty(shape=(set_length),dtype=object)\n",
    "gen_context = np.empty(shape=(set_length),dtype=object)\n",
    "labels = np.empty(shape=(set_length),dtype=int)\n",
    "\n",
    "assembly_lookup = []\n",
    "\n",
    "data_i = 0\n",
    "for ri, row in gen_data.iterrows():\n",
    "    assembly = row[\"Assembly Templates\"]\n",
    "    code = row[\"Code\"]\n",
    "\n",
    "    tokenized_code = code.split()\n",
    "    tokenized = assembly.split(\"\\n\")\n",
    "\n",
    "    for ti in range(len(tokenized)):\n",
    "        if (tokenized[ti] != end_char):\n",
    "            tokenized[ti] = f\"{ti}_{tokenized[ti]}\"\n",
    "\n",
    "        t = tokenized[ti]\n",
    "\n",
    "        if (not (t in assembly_lookup)):\n",
    "            assembly_lookup += [t]\n",
    "\n",
    "        code_context[data_i] = code\n",
    "        gen_context[data_i] = \"\\n\".join(tokenized[:ti])\n",
    "        labels[data_i] = assembly_lookup.index(tokenized[ti])\n",
    "        data_i += 1\n",
    "\n",
    "assembly_dict = {}\n",
    "for i in range(len(gen_context)):\n",
    "    assembly = gen_context[i]\n",
    "    for assembly_line in assembly.split(\"\\n\"):\n",
    "        if assembly_line in assembly_dict:\n",
    "            assembly_dict[assembly_line][\"count\"] += 1\n",
    "        else:\n",
    "            assembly_dict[assembly_line] = {\"count\": 1, \"index\": i}\n",
    "\n",
    "print(assembly_dict)\n",
    "\n",
    "for l in assembly_dict.keys():\n",
    "    item = assembly_dict[l]\n",
    "    c = item[\"count\"]\n",
    "    if c <= 5:\n",
    "        code_context = np.append(code_context, np.array(code_context[item[\"index\"]] * 10))\n",
    "        gen_context = np.append(gen_context, np.array(gen_context[item[\"index\"]] * 10))\n",
    "        labels = np.append(labels, np.array(labels[item[\"index\"]] * 10))\n",
    "        print(\"Warning: \" + l + \" only has \" + str(assembly_dict[l][\"count\"]) + \" instances; duplicating so it is not considered OoV\")\n",
    "\n",
    "gen_dataset = tf.data.Dataset.from_tensor_slices(({\"code\": code_context, \"assembly\": gen_context},labels)).batch(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(features, labels):\n",
    "  features = {\"code\": tf.strings.split(features[\"code\"]),\"assembly\": tf.strings.split(features[\"assembly\"],sep=\"\\n\")}\n",
    "  return features, labels\n",
    "\n",
    "gen_dataset = gen_dataset.map(prepare_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmp8dtpdiqs as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 24-03-03 20:15:28.4682 EST gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-03-03 20:15:28.4707 EST gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-03-03 20:15:28.4707 EST gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tensor examples:\n",
      "Features: {'code': tf.RaggedTensor(values=Tensor(\"data:0\", shape=(None,), dtype=string), row_splits=Tensor(\"data_1:0\", shape=(None,), dtype=int64)), 'assembly': tf.RaggedTensor(values=Tensor(\"data_2:0\", shape=(None,), dtype=string), row_splits=Tensor(\"data_3:0\", shape=(None,), dtype=int64))}\n",
      "Label: Tensor(\"data_4:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'code': SemanticTensor(semantic=<Semantic.CATEGORICAL_SET: 4>, tensor=tf.RaggedTensor(values=Tensor(\"data:0\", shape=(None,), dtype=string), row_splits=Tensor(\"data_1:0\", shape=(None,), dtype=int64))), 'assembly': SemanticTensor(semantic=<Semantic.CATEGORICAL_SET: 4>, tensor=tf.RaggedTensor(values=Tensor(\"data_2:0\", shape=(None,), dtype=string), row_splits=Tensor(\"data_3:0\", shape=(None,), dtype=int64)))}\n",
      "Training dataset read in 0:00:05.323976. Found 270787 examples.\n",
      "Training model...\n",
      "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-03-03 20:15:33.8643 EST kernel.cc:771] Start Yggdrasil model training\n",
      "[INFO 24-03-03 20:15:33.8643 EST kernel.cc:772] Collect training examples\n",
      "[INFO 24-03-03 20:15:33.8644 EST kernel.cc:785] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 24-03-03 20:15:33.8664 EST kernel.cc:391] Number of batches: 271\n",
      "[INFO 24-03-03 20:15:33.8664 EST kernel.cc:392] Number of examples: 270787\n",
      "[INFO 24-03-03 20:15:33.9994 EST data_spec_inference.cc:305] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column assembly (35 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "[INFO 24-03-03 20:15:34.1539 EST kernel.cc:792] Training dataset:\n",
      "Number of records: 270787\n",
      "Number of columns: 3\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL_SET: 2 (66.6667%)\n",
      "\tCATEGORICAL: 1 (33.3333%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL_SET: 2 (66.6667%)\n",
      "\t1: \"assembly\" CATEGORICAL_SET num-nas:30000 (11.0788%) has-dict vocab-size:36 num-oods:4 (0.00166122%) most-frequent:\"0_func(int, int):\" 240787 (100%)\n",
      "\t2: \"code\" CATEGORICAL_SET has-dict vocab-size:205 zero-ood-items most-frequent:\"1_*\" 90399 (33.3838%)\n",
      "\n",
      "CATEGORICAL: 1 (33.3333%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:112 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 24-03-03 20:15:34.1543 EST kernel.cc:808] Configure learner\n",
      "[WARNING 24-03-03 20:15:34.1545 EST gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-03-03 20:15:34.1545 EST gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-03-03 20:15:34.1545 EST gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 24-03-03 20:15:34.1546 EST kernel.cc:822] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^assembly$\"\n",
      "features: \"^code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  binary_focal_loss_options {\n",
      "    misprediction_exponent: 2\n",
      "    positive_sample_coefficient: 0.5\n",
      "  }\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "[INFO 24-03-03 20:15:34.1552 EST kernel.cc:825] Deployment config:\n",
      "cache_path: \"/tmp/tmp8dtpdiqs/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 24-03-03 20:15:34.1556 EST kernel.cc:887] Train model\n",
      "[WARNING 24-03-03 20:15:34.1557 EST gradient_boosted_trees.cc:3146] early_stopping != \"NONE\" requires validation_set_ratio>0. Setting early_stopping=\"NONE\" (was \"VALIDATION_LOSS_INCREASE\") i.e. sabling early stopping.\n",
      "[INFO 24-03-03 20:15:34.1559 EST gradient_boosted_trees.cc:591] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[WARNING 24-03-03 20:15:34.1559 EST gradient_boosted_trees.cc:623] The model configuration specifies 300 trees but computation of the validation loss will only start at iteration 10 with 111 trees per iteration. No validation loss will be computed, early stopping is not used.\n",
      "[INFO 24-03-03 20:15:34.1559 EST gradient_boosted_trees.cc:1218] Training gradient boosted tree on 270787 example(s) and 2 feature(s).\n",
      "[INFO 24-03-03 20:15:34.1564 EST gradient_boosted_trees.cc:1261] 270787 examples used for training and 0 examples used for validation\n",
      "[INFO 24-03-03 20:15:56.1603 EST gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:2.135797 train-accuracy:0.412693\n",
      "[INFO 24-03-03 20:16:57.4516 EST gradient_boosted_trees.cc:1638] \tnum-trees:2 train-loss:1.633171 train-accuracy:0.670516\n",
      "[INFO 24-03-03 20:18:01.3425 EST gradient_boosted_trees.cc:1638] \tnum-trees:3 train-loss:1.232439 train-accuracy:0.782286\n",
      "[INFO 24-03-03 20:19:01.0068 EST gradient_boosted_trees.cc:1638] \tnum-trees:4 train-loss:1.083161 train-accuracy:0.831192\n",
      "[INFO 24-03-03 20:19:56.4302 EST gradient_boosted_trees.cc:1638] \tnum-trees:5 train-loss:0.937644 train-accuracy:0.939015\n",
      "[INFO 24-03-03 20:20:53.5483 EST gradient_boosted_trees.cc:1638] \tnum-trees:6 train-loss:0.825791 train-accuracy:0.964334\n",
      "[INFO 24-03-03 20:21:49.1481 EST gradient_boosted_trees.cc:1638] \tnum-trees:7 train-loss:0.719772 train-accuracy:0.968547\n",
      "[INFO 24-03-03 20:22:44.2395 EST gradient_boosted_trees.cc:1638] \tnum-trees:8 train-loss:0.653638 train-accuracy:0.968795\n",
      "[INFO 24-03-03 20:23:38.5872 EST gradient_boosted_trees.cc:1638] \tnum-trees:9 train-loss:0.560922 train-accuracy:0.969090\n",
      "[INFO 24-03-03 20:24:34.7586 EST gradient_boosted_trees.cc:1638] \tnum-trees:10 train-loss:0.489986 train-accuracy:0.975043\n",
      "[INFO 24-03-03 20:25:30.2483 EST gradient_boosted_trees.cc:1638] \tnum-trees:11 train-loss:0.439204 train-accuracy:0.997962\n",
      "[INFO 24-03-03 20:26:27.8460 EST gradient_boosted_trees.cc:1638] \tnum-trees:12 train-loss:0.388591 train-accuracy:0.997755\n",
      "[INFO 24-03-03 20:27:33.6634 EST gradient_boosted_trees.cc:1638] \tnum-trees:13 train-loss:0.346385 train-accuracy:0.998146\n",
      "[INFO 24-03-03 20:28:27.4855 EST gradient_boosted_trees.cc:1638] \tnum-trees:14 train-loss:0.303261 train-accuracy:0.998124\n",
      "[INFO 24-03-03 20:29:21.9233 EST gradient_boosted_trees.cc:1638] \tnum-trees:15 train-loss:0.279878 train-accuracy:0.998346\n",
      "[INFO 24-03-03 20:30:25.9645 EST gradient_boosted_trees.cc:1638] \tnum-trees:16 train-loss:0.245686 train-accuracy:0.998231\n",
      "[INFO 24-03-03 20:31:38.1793 EST gradient_boosted_trees.cc:1638] \tnum-trees:17 train-loss:0.217038 train-accuracy:0.998246\n",
      "[INFO 24-03-03 20:32:40.6462 EST gradient_boosted_trees.cc:1638] \tnum-trees:18 train-loss:0.184084 train-accuracy:0.998323\n",
      "[INFO 24-03-03 20:33:34.3615 EST gradient_boosted_trees.cc:1638] \tnum-trees:19 train-loss:0.166748 train-accuracy:0.998419\n",
      "[INFO 24-03-03 20:34:29.7482 EST gradient_boosted_trees.cc:1638] \tnum-trees:20 train-loss:0.146661 train-accuracy:0.998434\n",
      "[INFO 24-03-03 20:35:22.9178 EST gradient_boosted_trees.cc:1638] \tnum-trees:21 train-loss:0.125354 train-accuracy:0.998438\n",
      "[INFO 24-03-03 20:36:15.1313 EST gradient_boosted_trees.cc:1638] \tnum-trees:22 train-loss:0.111697 train-accuracy:0.998482\n",
      "[INFO 24-03-03 20:37:08.3557 EST gradient_boosted_trees.cc:1638] \tnum-trees:23 train-loss:0.100707 train-accuracy:0.998490\n",
      "[INFO 24-03-03 20:38:01.4104 EST gradient_boosted_trees.cc:1638] \tnum-trees:24 train-loss:0.091070 train-accuracy:0.998748\n",
      "[INFO 24-03-03 20:38:53.9318 EST gradient_boosted_trees.cc:1638] \tnum-trees:25 train-loss:0.081158 train-accuracy:0.998818\n",
      "[INFO 24-03-03 20:39:45.5659 EST gradient_boosted_trees.cc:1638] \tnum-trees:26 train-loss:0.071903 train-accuracy:0.998837\n",
      "[INFO 24-03-03 20:40:38.5298 EST gradient_boosted_trees.cc:1638] \tnum-trees:27 train-loss:0.064367 train-accuracy:0.998840\n",
      "[INFO 24-03-03 20:41:33.7901 EST gradient_boosted_trees.cc:1638] \tnum-trees:28 train-loss:0.058002 train-accuracy:0.998848\n",
      "[INFO 24-03-03 20:42:24.8754 EST gradient_boosted_trees.cc:1638] \tnum-trees:29 train-loss:0.052022 train-accuracy:0.998970\n",
      "[INFO 24-03-03 20:43:17.1175 EST gradient_boosted_trees.cc:1638] \tnum-trees:30 train-loss:0.046796 train-accuracy:0.999010\n",
      "[INFO 24-03-03 20:44:09.4315 EST gradient_boosted_trees.cc:1638] \tnum-trees:31 train-loss:0.043935 train-accuracy:0.999417\n",
      "[INFO 24-03-03 20:45:00.4875 EST gradient_boosted_trees.cc:1638] \tnum-trees:32 train-loss:0.039168 train-accuracy:0.999420\n",
      "[INFO 24-03-03 20:45:51.9394 EST gradient_boosted_trees.cc:1638] \tnum-trees:33 train-loss:0.036826 train-accuracy:0.999487\n",
      "[INFO 24-03-03 20:45:51.9394 EST gradient_boosted_trees.cc:1661] Create a snapshot of the model at iteration 32\n",
      "[INFO 24-03-03 20:46:42.9915 EST gradient_boosted_trees.cc:1638] \tnum-trees:34 train-loss:0.033495 train-accuracy:0.999549\n",
      "[INFO 24-03-03 20:47:34.4029 EST gradient_boosted_trees.cc:1638] \tnum-trees:35 train-loss:0.029995 train-accuracy:0.999649\n",
      "[INFO 24-03-03 20:48:25.0616 EST gradient_boosted_trees.cc:1638] \tnum-trees:36 train-loss:0.026732 train-accuracy:0.999697\n",
      "[INFO 24-03-03 20:49:14.4402 EST gradient_boosted_trees.cc:1638] \tnum-trees:37 train-loss:0.024193 train-accuracy:0.999690\n",
      "[INFO 24-03-03 20:50:04.5685 EST gradient_boosted_trees.cc:1638] \tnum-trees:38 train-loss:0.022105 train-accuracy:0.999664\n",
      "[INFO 24-03-03 20:50:53.7604 EST gradient_boosted_trees.cc:1638] \tnum-trees:39 train-loss:0.020378 train-accuracy:0.999756\n",
      "[INFO 24-03-03 20:51:45.1147 EST gradient_boosted_trees.cc:1638] \tnum-trees:40 train-loss:0.018617 train-accuracy:0.999760\n",
      "[INFO 24-03-03 20:52:35.2156 EST gradient_boosted_trees.cc:1638] \tnum-trees:41 train-loss:0.017010 train-accuracy:0.999789\n",
      "[INFO 24-03-03 20:53:25.9990 EST gradient_boosted_trees.cc:1638] \tnum-trees:42 train-loss:0.015783 train-accuracy:0.999838\n",
      "[INFO 24-03-03 20:54:14.3098 EST gradient_boosted_trees.cc:1638] \tnum-trees:43 train-loss:0.014561 train-accuracy:0.999849\n",
      "[INFO 24-03-03 20:55:03.5369 EST gradient_boosted_trees.cc:1638] \tnum-trees:44 train-loss:0.013538 train-accuracy:0.999871\n",
      "[INFO 24-03-03 20:55:54.8605 EST gradient_boosted_trees.cc:1638] \tnum-trees:45 train-loss:0.012789 train-accuracy:0.999889\n",
      "[INFO 24-03-03 20:56:46.0444 EST gradient_boosted_trees.cc:1638] \tnum-trees:46 train-loss:0.011784 train-accuracy:0.999897\n",
      "[INFO 24-03-03 20:57:34.8956 EST gradient_boosted_trees.cc:1638] \tnum-trees:47 train-loss:0.010800 train-accuracy:0.999900\n",
      "[INFO 24-03-03 20:58:26.1778 EST gradient_boosted_trees.cc:1638] \tnum-trees:48 train-loss:0.009875 train-accuracy:0.999900\n",
      "[INFO 24-03-03 20:59:15.1953 EST gradient_boosted_trees.cc:1638] \tnum-trees:49 train-loss:0.009419 train-accuracy:0.999922\n",
      "[INFO 24-03-03 21:00:05.8999 EST gradient_boosted_trees.cc:1638] \tnum-trees:50 train-loss:0.008459 train-accuracy:0.999915\n",
      "[INFO 24-03-03 21:00:55.1725 EST gradient_boosted_trees.cc:1638] \tnum-trees:51 train-loss:0.007534 train-accuracy:0.999915\n",
      "[INFO 24-03-03 21:01:45.3400 EST gradient_boosted_trees.cc:1638] \tnum-trees:52 train-loss:0.006913 train-accuracy:0.999919\n",
      "[INFO 24-03-03 21:02:33.1770 EST gradient_boosted_trees.cc:1638] \tnum-trees:53 train-loss:0.006702 train-accuracy:0.999926\n",
      "[INFO 24-03-03 21:03:24.4111 EST gradient_boosted_trees.cc:1638] \tnum-trees:54 train-loss:0.006186 train-accuracy:0.999937\n",
      "[INFO 24-03-03 21:04:14.1066 EST gradient_boosted_trees.cc:1638] \tnum-trees:55 train-loss:0.005827 train-accuracy:0.999941\n",
      "[INFO 24-03-03 21:05:05.1793 EST gradient_boosted_trees.cc:1638] \tnum-trees:56 train-loss:0.005402 train-accuracy:0.999941\n",
      "[INFO 24-03-03 21:05:56.1015 EST gradient_boosted_trees.cc:1638] \tnum-trees:57 train-loss:0.004961 train-accuracy:0.999945\n",
      "[INFO 24-03-03 21:06:47.4940 EST gradient_boosted_trees.cc:1638] \tnum-trees:58 train-loss:0.004608 train-accuracy:0.999945\n",
      "[INFO 24-03-03 21:07:38.0186 EST gradient_boosted_trees.cc:1638] \tnum-trees:59 train-loss:0.004375 train-accuracy:0.999948\n",
      "[INFO 24-03-03 21:08:27.9923 EST gradient_boosted_trees.cc:1638] \tnum-trees:60 train-loss:0.004119 train-accuracy:0.999952\n",
      "[INFO 24-03-03 21:09:17.9120 EST gradient_boosted_trees.cc:1638] \tnum-trees:61 train-loss:0.003875 train-accuracy:0.999956\n",
      "[INFO 24-03-03 21:10:08.9801 EST gradient_boosted_trees.cc:1638] \tnum-trees:62 train-loss:0.003615 train-accuracy:0.999963\n",
      "[INFO 24-03-03 21:11:00.0982 EST gradient_boosted_trees.cc:1638] \tnum-trees:63 train-loss:0.003475 train-accuracy:0.999970\n",
      "[INFO 24-03-03 21:11:53.2069 EST gradient_boosted_trees.cc:1638] \tnum-trees:64 train-loss:0.003325 train-accuracy:0.999967\n",
      "[INFO 24-03-03 21:12:44.9178 EST gradient_boosted_trees.cc:1638] \tnum-trees:65 train-loss:0.003152 train-accuracy:0.999978\n",
      "[INFO 24-03-03 21:13:36.7464 EST gradient_boosted_trees.cc:1638] \tnum-trees:66 train-loss:0.002933 train-accuracy:0.999982\n",
      "[INFO 24-03-03 21:14:31.5786 EST gradient_boosted_trees.cc:1638] \tnum-trees:67 train-loss:0.002767 train-accuracy:0.999982\n",
      "[INFO 24-03-03 21:15:25.2154 EST gradient_boosted_trees.cc:1638] \tnum-trees:68 train-loss:0.002515 train-accuracy:0.999982\n",
      "[INFO 24-03-03 21:16:20.1655 EST gradient_boosted_trees.cc:1638] \tnum-trees:69 train-loss:0.002318 train-accuracy:0.999982\n",
      "[INFO 24-03-03 21:16:20.1655 EST gradient_boosted_trees.cc:1661] Create a snapshot of the model at iteration 68\n",
      "[INFO 24-03-03 21:17:13.5038 EST gradient_boosted_trees.cc:1638] \tnum-trees:70 train-loss:0.002139 train-accuracy:0.999982\n",
      "[INFO 24-03-03 21:18:08.5367 EST gradient_boosted_trees.cc:1638] \tnum-trees:71 train-loss:0.002039 train-accuracy:0.999982\n",
      "[INFO 24-03-03 21:19:33.3453 EST gradient_boosted_trees.cc:1638] \tnum-trees:72 train-loss:0.001850 train-accuracy:0.999989\n",
      "[INFO 24-03-03 21:20:48.5196 EST gradient_boosted_trees.cc:1638] \tnum-trees:73 train-loss:0.001734 train-accuracy:0.999993\n",
      "[INFO 24-03-03 21:21:44.1609 EST gradient_boosted_trees.cc:1638] \tnum-trees:74 train-loss:0.001684 train-accuracy:0.999993\n",
      "[INFO 24-03-03 21:22:39.1109 EST gradient_boosted_trees.cc:1638] \tnum-trees:75 train-loss:0.001584 train-accuracy:0.999993\n",
      "[INFO 24-03-03 21:23:34.9179 EST gradient_boosted_trees.cc:1638] \tnum-trees:76 train-loss:0.001491 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:24:32.0189 EST gradient_boosted_trees.cc:1638] \tnum-trees:77 train-loss:0.001389 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:25:32.7818 EST gradient_boosted_trees.cc:1638] \tnum-trees:78 train-loss:0.001286 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:26:31.9974 EST gradient_boosted_trees.cc:1638] \tnum-trees:79 train-loss:0.001240 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:27:29.7208 EST gradient_boosted_trees.cc:1638] \tnum-trees:80 train-loss:0.001186 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:28:28.0314 EST gradient_boosted_trees.cc:1638] \tnum-trees:81 train-loss:0.001125 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:29:26.9506 EST gradient_boosted_trees.cc:1638] \tnum-trees:82 train-loss:0.001074 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:30:23.9213 EST gradient_boosted_trees.cc:1638] \tnum-trees:83 train-loss:0.001008 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:31:21.5715 EST gradient_boosted_trees.cc:1638] \tnum-trees:84 train-loss:0.000974 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:32:22.3650 EST gradient_boosted_trees.cc:1638] \tnum-trees:85 train-loss:0.000932 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:33:19.7101 EST gradient_boosted_trees.cc:1638] \tnum-trees:86 train-loss:0.000906 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:34:19.6420 EST gradient_boosted_trees.cc:1638] \tnum-trees:87 train-loss:0.000819 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:35:18.4317 EST gradient_boosted_trees.cc:1638] \tnum-trees:88 train-loss:0.000758 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:36:21.7371 EST gradient_boosted_trees.cc:1638] \tnum-trees:89 train-loss:0.000722 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:37:21.0167 EST gradient_boosted_trees.cc:1638] \tnum-trees:90 train-loss:0.000681 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:38:23.6173 EST gradient_boosted_trees.cc:1638] \tnum-trees:91 train-loss:0.000631 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:39:26.8674 EST gradient_boosted_trees.cc:1638] \tnum-trees:92 train-loss:0.000601 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:40:30.0769 EST gradient_boosted_trees.cc:1638] \tnum-trees:93 train-loss:0.000571 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:41:32.2132 EST gradient_boosted_trees.cc:1638] \tnum-trees:94 train-loss:0.000547 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:42:34.2893 EST gradient_boosted_trees.cc:1638] \tnum-trees:95 train-loss:0.000516 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:43:38.2361 EST gradient_boosted_trees.cc:1638] \tnum-trees:96 train-loss:0.000491 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:44:41.0106 EST gradient_boosted_trees.cc:1638] \tnum-trees:97 train-loss:0.000466 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:45:43.7929 EST gradient_boosted_trees.cc:1638] \tnum-trees:98 train-loss:0.000441 train-accuracy:0.999996\n",
      "[INFO 24-03-03 21:46:45.3394 EST gradient_boosted_trees.cc:1638] \tnum-trees:99 train-loss:0.000408 train-accuracy:1.000000\n",
      "[INFO 24-03-03 21:46:45.3394 EST gradient_boosted_trees.cc:1661] Create a snapshot of the model at iteration 98\n",
      "[INFO 24-03-03 21:47:51.3114 EST gradient_boosted_trees.cc:1638] \tnum-trees:100 train-loss:0.000384 train-accuracy:1.000000\n",
      "[INFO 24-03-03 21:48:54.9619 EST gradient_boosted_trees.cc:1638] \tnum-trees:101 train-loss:0.000365 train-accuracy:1.000000\n",
      "[INFO 24-03-03 21:49:56.8321 EST gradient_boosted_trees.cc:1638] \tnum-trees:102 train-loss:0.000352 train-accuracy:1.000000\n",
      "[INFO 24-03-03 21:51:00.6074 EST gradient_boosted_trees.cc:1638] \tnum-trees:103 train-loss:0.000342 train-accuracy:1.000000\n",
      "[INFO 24-03-03 21:52:03.9526 EST gradient_boosted_trees.cc:1638] \tnum-trees:104 train-loss:0.000312 train-accuracy:1.000000\n",
      "[INFO 24-03-03 21:53:07.9438 EST gradient_boosted_trees.cc:1638] \tnum-trees:105 train-loss:0.000292 train-accuracy:1.000000\n",
      "[INFO 24-03-03 21:54:13.2021 EST gradient_boosted_trees.cc:1638] \tnum-trees:106 train-loss:0.000282 train-accuracy:1.000000\n",
      "[INFO 24-03-03 21:55:16.1504 EST gradient_boosted_trees.cc:1638] \tnum-trees:107 train-loss:0.000265 train-accuracy:1.000000\n",
      "[INFO 24-03-03 21:56:21.1385 EST gradient_boosted_trees.cc:1638] \tnum-trees:108 train-loss:0.000248 train-accuracy:1.000000\n",
      "[INFO 24-03-03 21:57:25.3205 EST gradient_boosted_trees.cc:1638] \tnum-trees:109 train-loss:0.000234 train-accuracy:1.000000\n",
      "[INFO 24-03-03 21:58:29.6955 EST gradient_boosted_trees.cc:1638] \tnum-trees:110 train-loss:0.000221 train-accuracy:1.000000\n",
      "[INFO 24-03-03 21:59:34.0258 EST gradient_boosted_trees.cc:1638] \tnum-trees:111 train-loss:0.000208 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:00:39.5791 EST gradient_boosted_trees.cc:1638] \tnum-trees:112 train-loss:0.000198 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:01:45.6514 EST gradient_boosted_trees.cc:1638] \tnum-trees:113 train-loss:0.000189 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:02:46.9065 EST gradient_boosted_trees.cc:1638] \tnum-trees:114 train-loss:0.000180 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:03:51.8486 EST gradient_boosted_trees.cc:1638] \tnum-trees:115 train-loss:0.000171 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:04:56.1607 EST gradient_boosted_trees.cc:1638] \tnum-trees:116 train-loss:0.000164 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:05:59.8358 EST gradient_boosted_trees.cc:1638] \tnum-trees:117 train-loss:0.000156 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:07:03.3400 EST gradient_boosted_trees.cc:1638] \tnum-trees:118 train-loss:0.000150 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:08:07.7514 EST gradient_boosted_trees.cc:1638] \tnum-trees:119 train-loss:0.000140 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:09:09.4832 EST gradient_boosted_trees.cc:1638] \tnum-trees:120 train-loss:0.000136 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:10:11.1475 EST gradient_boosted_trees.cc:1638] \tnum-trees:121 train-loss:0.000130 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:11:12.7470 EST gradient_boosted_trees.cc:1638] \tnum-trees:122 train-loss:0.000123 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:12:17.4621 EST gradient_boosted_trees.cc:1638] \tnum-trees:123 train-loss:0.000116 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:13:19.7897 EST gradient_boosted_trees.cc:1638] \tnum-trees:124 train-loss:0.000110 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:14:24.9215 EST gradient_boosted_trees.cc:1638] \tnum-trees:125 train-loss:0.000104 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:15:29.2204 EST gradient_boosted_trees.cc:1638] \tnum-trees:126 train-loss:0.000101 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:16:31.5310 EST gradient_boosted_trees.cc:1638] \tnum-trees:127 train-loss:0.000098 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:17:33.7753 EST gradient_boosted_trees.cc:1638] \tnum-trees:128 train-loss:0.000095 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:17:33.7754 EST gradient_boosted_trees.cc:1661] Create a snapshot of the model at iteration 127\n",
      "[INFO 24-03-03 22:17:34.2326 EST gradient_boosted_trees.cc:166] Remove snapshot of the model at iteration 32\n",
      "[INFO 24-03-03 22:18:33.8244 EST gradient_boosted_trees.cc:1638] \tnum-trees:129 train-loss:0.000091 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:19:38.9805 EST gradient_boosted_trees.cc:1638] \tnum-trees:130 train-loss:0.000086 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:20:42.2957 EST gradient_boosted_trees.cc:1638] \tnum-trees:131 train-loss:0.000082 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:21:44.9454 EST gradient_boosted_trees.cc:1638] \tnum-trees:132 train-loss:0.000079 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:22:48.7806 EST gradient_boosted_trees.cc:1638] \tnum-trees:133 train-loss:0.000076 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:23:50.6997 EST gradient_boosted_trees.cc:1638] \tnum-trees:134 train-loss:0.000072 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:24:54.7388 EST gradient_boosted_trees.cc:1638] \tnum-trees:135 train-loss:0.000069 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:25:59.9982 EST gradient_boosted_trees.cc:1638] \tnum-trees:136 train-loss:0.000067 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:27:06.2192 EST gradient_boosted_trees.cc:1638] \tnum-trees:137 train-loss:0.000065 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:28:06.8623 EST gradient_boosted_trees.cc:1638] \tnum-trees:138 train-loss:0.000062 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:29:09.1624 EST gradient_boosted_trees.cc:1638] \tnum-trees:139 train-loss:0.000060 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:30:11.1584 EST gradient_boosted_trees.cc:1638] \tnum-trees:140 train-loss:0.000058 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:31:13.7546 EST gradient_boosted_trees.cc:1638] \tnum-trees:141 train-loss:0.000056 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:32:16.7212 EST gradient_boosted_trees.cc:1638] \tnum-trees:142 train-loss:0.000053 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:33:19.2579 EST gradient_boosted_trees.cc:1638] \tnum-trees:143 train-loss:0.000051 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:34:21.4046 EST gradient_boosted_trees.cc:1638] \tnum-trees:144 train-loss:0.000049 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:35:25.4035 EST gradient_boosted_trees.cc:1638] \tnum-trees:145 train-loss:0.000046 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:36:27.1327 EST gradient_boosted_trees.cc:1638] \tnum-trees:146 train-loss:0.000044 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:37:30.7187 EST gradient_boosted_trees.cc:1638] \tnum-trees:147 train-loss:0.000043 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:38:33.3755 EST gradient_boosted_trees.cc:1638] \tnum-trees:148 train-loss:0.000041 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:39:35.6962 EST gradient_boosted_trees.cc:1638] \tnum-trees:149 train-loss:0.000039 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:40:38.4617 EST gradient_boosted_trees.cc:1638] \tnum-trees:150 train-loss:0.000038 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:41:43.1469 EST gradient_boosted_trees.cc:1638] \tnum-trees:151 train-loss:0.000036 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:42:43.8348 EST gradient_boosted_trees.cc:1638] \tnum-trees:152 train-loss:0.000035 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:43:55.0983 EST gradient_boosted_trees.cc:1638] \tnum-trees:153 train-loss:0.000033 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:44:59.4436 EST gradient_boosted_trees.cc:1638] \tnum-trees:154 train-loss:0.000032 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:46:05.1793 EST gradient_boosted_trees.cc:1638] \tnum-trees:155 train-loss:0.000031 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:47:12.8359 EST gradient_boosted_trees.cc:1638] \tnum-trees:156 train-loss:0.000030 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:48:14.8548 EST gradient_boosted_trees.cc:1638] \tnum-trees:157 train-loss:0.000028 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:48:14.8548 EST gradient_boosted_trees.cc:1661] Create a snapshot of the model at iteration 156\n",
      "[INFO 24-03-03 22:48:15.3885 EST gradient_boosted_trees.cc:166] Remove snapshot of the model at iteration 68\n",
      "[INFO 24-03-03 22:49:17.4249 EST gradient_boosted_trees.cc:1638] \tnum-trees:158 train-loss:0.000028 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:50:22.5807 EST gradient_boosted_trees.cc:1638] \tnum-trees:159 train-loss:0.000027 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:51:25.6483 EST gradient_boosted_trees.cc:1638] \tnum-trees:160 train-loss:0.000026 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:52:28.1426 EST gradient_boosted_trees.cc:1638] \tnum-trees:161 train-loss:0.000024 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:53:32.3920 EST gradient_boosted_trees.cc:1638] \tnum-trees:162 train-loss:0.000023 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:54:35.7318 EST gradient_boosted_trees.cc:1638] \tnum-trees:163 train-loss:0.000023 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:55:40.8747 EST gradient_boosted_trees.cc:1638] \tnum-trees:164 train-loss:0.000022 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:56:42.8557 EST gradient_boosted_trees.cc:1638] \tnum-trees:165 train-loss:0.000021 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:57:47.9680 EST gradient_boosted_trees.cc:1638] \tnum-trees:166 train-loss:0.000020 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:58:49.3679 EST gradient_boosted_trees.cc:1638] \tnum-trees:167 train-loss:0.000020 train-accuracy:1.000000\n",
      "[INFO 24-03-03 22:59:52.1508 EST gradient_boosted_trees.cc:1638] \tnum-trees:168 train-loss:0.000019 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:00:54.1119 EST gradient_boosted_trees.cc:1638] \tnum-trees:169 train-loss:0.000018 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:01:56.2472 EST gradient_boosted_trees.cc:1638] \tnum-trees:170 train-loss:0.000018 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:02:59.1835 EST gradient_boosted_trees.cc:1638] \tnum-trees:171 train-loss:0.000017 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:03:58.4810 EST gradient_boosted_trees.cc:1638] \tnum-trees:172 train-loss:0.000017 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:05:00.1508 EST gradient_boosted_trees.cc:1638] \tnum-trees:173 train-loss:0.000016 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:06:01.1279 EST gradient_boosted_trees.cc:1638] \tnum-trees:174 train-loss:0.000015 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:07:04.3348 EST gradient_boosted_trees.cc:1638] \tnum-trees:175 train-loss:0.000015 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:08:05.2867 EST gradient_boosted_trees.cc:1638] \tnum-trees:176 train-loss:0.000014 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:09:05.0806 EST gradient_boosted_trees.cc:1638] \tnum-trees:177 train-loss:0.000014 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:10:04.8331 EST gradient_boosted_trees.cc:1638] \tnum-trees:178 train-loss:0.000013 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:11:09.3076 EST gradient_boosted_trees.cc:1638] \tnum-trees:179 train-loss:0.000012 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:12:11.3256 EST gradient_boosted_trees.cc:1638] \tnum-trees:180 train-loss:0.000012 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:13:15.2068 EST gradient_boosted_trees.cc:1638] \tnum-trees:181 train-loss:0.000011 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:14:19.9622 EST gradient_boosted_trees.cc:1638] \tnum-trees:182 train-loss:0.000011 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:15:22.0830 EST gradient_boosted_trees.cc:1638] \tnum-trees:183 train-loss:0.000011 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:16:24.8301 EST gradient_boosted_trees.cc:1638] \tnum-trees:184 train-loss:0.000010 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:17:37.6691 EST gradient_boosted_trees.cc:1638] \tnum-trees:185 train-loss:0.000010 train-accuracy:1.000000\n",
      "[INFO 24-03-03 23:17:37.6691 EST gradient_boosted_trees.cc:1435] Training interrupted per request.\n",
      "[INFO 24-03-03 23:17:37.6691 EST gradient_boosted_trees.cc:1675] Create final snapshot of the model at iteration 185\n",
      "[INFO 24-03-03 23:17:38.3168 EST gradient_boosted_trees.cc:166] Remove snapshot of the model at iteration 98\n",
      "[INFO 24-03-03 23:17:38.5027 EST kernel.cc:919] Export model in log directory: /tmp/tmp8dtpdiqs with prefix 36259cac46584f6a\n",
      "[INFO 24-03-03 23:17:39.1785 EST kernel.cc:937] Save model in resources\n",
      "[WARNING 24-03-03 23:17:39.2160 EST gradient_boosted_trees.cc:514] Validation evaluation not available for the Gradient Boosted Tree model as no validation dataset was provided for training (i.e. validation_set_ratio == 0).\n",
      "[INFO 24-03-03 23:17:39.8006 EST kernel.cc:1233] Loading model from path /tmp/tmp8dtpdiqs/model/ with prefix 36259cac46584f6a\n",
      "[INFO 24-03-03 23:17:43.2252 EST decision_forest.cc:660] Model loaded with 20535 root(s), 990825 node(s), and 2 input feature(s).\n",
      "[INFO 24-03-03 23:17:43.2253 EST abstract_model.cc:1344] Engine \"GradientBoostedTreesGeneric\" built\n",
      "[INFO 24-03-03 23:17:43.2253 EST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 3:02:09.775624\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f37415cd900>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tuner = tfdf.tuner.RandomSearch(num_trials=50, use_predefined_hps=True)\n",
    "# We want to overfit, since this is a compilation problem and we are training on all the inputs.\n",
    "gen_model = tfdf.keras.GradientBoostedTreesModel(validation_ratio=0.0)\n",
    "gen_model.fit(gen_dataset, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_line(code, context = \"\"):\n",
    "    return np.argmax(gen_model({\"code\":tf.strings.split([code]), \"assembly\":tf.strings.split([context],sep=\"\\n\")})[0])\n",
    "\n",
    "def generate_template(code, sanity=50):\n",
    "    code = re.sub(r'([\\{\\};\\(\\)\\,])', r' \\1 ', code)\n",
    "    interim = \"\"\n",
    "    while not interim.endswith(end_char + \"\\n\") and sanity > 0:\n",
    "        interim += assembly_lookup[generate_line(code,interim)] + \"\\n\"\n",
    "        sanity -= 1\n",
    "    return interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 8 thread(s) for training\n",
      "Use /tmp/tmpux8ytm50 as temporary training directory\n",
      "Reading training dataset...\n",
      "Training tensor examples:\n",
      "Features: {'features': tf.RaggedTensor(values=Tensor(\"data:0\", shape=(None,), dtype=string), row_splits=Tensor(\"data_1:0\", shape=(None,), dtype=int64))}\n",
      "Label: Tensor(\"data_2:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'features': SemanticTensor(semantic=<Semantic.CATEGORICAL_SET: 4>, tensor=tf.RaggedTensor(values=Tensor(\"data:0\", shape=(None,), dtype=string), row_splits=Tensor(\"data_1:0\", shape=(None,), dtype=int64)))}\n",
      "Training dataset read in 0:00:00.296164. Found 30000 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-03-03 23:18:26.0009 EST kernel.cc:771] Start Yggdrasil model training\n",
      "[INFO 24-03-03 23:18:26.0009 EST kernel.cc:772] Collect training examples\n",
      "[INFO 24-03-03 23:18:26.0011 EST kernel.cc:785] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 24-03-03 23:18:26.0035 EST kernel.cc:391] Number of batches: 30\n",
      "[INFO 24-03-03 23:18:26.0035 EST kernel.cc:392] Number of examples: 30000\n",
      "[INFO 24-03-03 23:18:26.0125 EST kernel.cc:792] Training dataset:\n",
      "Number of records: 30000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL_SET: 1 (50%)\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL_SET: 1 (50%)\n",
      "\t1: \"features\" CATEGORICAL_SET has-dict vocab-size:204 zero-ood-items most-frequent:\"1_*\" 10000 (33.3333%)\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 24-03-03 23:18:26.0129 EST kernel.cc:808] Configure learner\n",
      "[INFO 24-03-03 23:18:26.0132 EST kernel.cc:822] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^features$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 50\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "[INFO 24-03-03 23:18:26.0147 EST kernel.cc:825] Deployment config:\n",
      "cache_path: \"/tmp/tmpux8ytm50/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 24-03-03 23:18:26.0151 EST kernel.cc:887] Train model\n",
      "[INFO 24-03-03 23:18:26.0156 EST random_forest.cc:416] Training random forest on 30000 example(s) and 1 feature(s).\n",
      "[INFO 24-03-03 23:18:26.0591 EST random_forest.cc:802] Training of tree  1/50 (tree index:0) done accuracy:1 logloss:0\n",
      "[INFO 24-03-03 23:18:26.2337 EST random_forest.cc:802] Training of tree  11/50 (tree index:14) done accuracy:0.998859 logloss:0.0157143\n",
      "[INFO 24-03-03 23:18:26.4468 EST random_forest.cc:802] Training of tree  21/50 (tree index:18) done accuracy:0.9993 logloss:0.0443458\n",
      "[INFO 24-03-03 23:18:26.7037 EST random_forest.cc:802] Training of tree  31/50 (tree index:36) done accuracy:1 logloss:0.0439984\n",
      "[INFO 24-03-03 23:18:26.9398 EST random_forest.cc:802] Training of tree  41/50 (tree index:44) done accuracy:1 logloss:0.0564477\n",
      "[INFO 24-03-03 23:18:27.1530 EST random_forest.cc:802] Training of tree  50/50 (tree index:47) done accuracy:1 logloss:0.060008\n",
      "[INFO 24-03-03 23:18:27.1538 EST random_forest.cc:882] Final OOB metrics: accuracy:1 logloss:0.060008\n",
      "[INFO 24-03-03 23:18:27.1573 EST kernel.cc:919] Export model in log directory: /tmp/tmpux8ytm50 with prefix 9218bea5b2a3489a\n",
      "[INFO 24-03-03 23:18:27.1643 EST kernel.cc:937] Save model in resources\n",
      "[INFO 24-03-03 23:18:27.1739 EST abstract_model.cc:881] Model self evaluation:\n",
      "Number of predictions (without weights): 30000\n",
      "Number of predictions (with weights): 30000\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 1  CI95[W][0.9999 1]\n",
      "LogLoss: : 0.060008\n",
      "ErrorRate: : 0\n",
      "\n",
      "Default Accuracy: : 0.333333\n",
      "Default LogLoss: : 1.09861\n",
      "Default ErrorRate: : 0.666667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "       1      2      3\n",
      "1  10000      0      0\n",
      "2      0  10000      0\n",
      "3      0      0  10000\n",
      "Total: 30000\n",
      "\n",
      "\n",
      "[INFO 24-03-03 23:18:27.1913 EST kernel.cc:1233] Loading model from path /tmp/tmpux8ytm50/model/ with prefix 9218bea5b2a3489a\n",
      "[INFO 24-03-03 23:18:27.2280 EST decision_forest.cc:660] Model loaded with 50 root(s), 6498 node(s), and 1 input feature(s).\n",
      "[INFO 24-03-03 23:18:27.2280 EST abstract_model.cc:1344] Engine \"RandomForestGeneric\" built\n",
      "[INFO 24-03-03 23:18:27.2280 EST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:01.238422\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    }
   ],
   "source": [
    "pf = pd.concat([data[\"Code\"],data[\"Mapped Operator\"]],axis=1)\n",
    "pf = pf.rename(columns={\"Code\": \"features\", \"Mapped Operator\": \"labels\"})\n",
    "tf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(pf, label=\"labels\")\n",
    "\n",
    "def prepare_dataset(features, labels):\n",
    "  features = {\"features\": tf.strings.split(features[\"features\"])}\n",
    "  return features, labels\n",
    "\n",
    "tf_dataset = tf_dataset.map(prepare_dataset)\n",
    "\n",
    "op_model = tfdf.keras.RandomForestModel(num_trees=50,verbose=2)\n",
    "op_history = op_model.fit(tf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_operator(code):\n",
    "    return np.argmax(op_model.call({\"features\": tf.strings.split([code])})[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_247856/837620651.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  relevant_data[\"Code Digits\"] = relevant_data[\"Code Digits\"].apply(lambda x: x + ([0] * (3-len(x))))\n",
      "/tmp/ipykernel_247856/837620651.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  relevant_data[\"Assembly Digits\"] = relevant_data[\"Assembly Digits\"].apply(lambda x: x + ([0] * (3-len(x))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 23:18:41.083661: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f37484cb7d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-03 23:18:41.084070: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1050, Compute Capability 6.1\n",
      "2024-03-03 23:18:41.231428: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-03 23:18:41.430309: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1709525921.698469  247903 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 6s 9ms/step - loss: 33.3178 - val_loss: 1.6334e-04\n",
      "Epoch 2/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 1.2938e-04 - val_loss: 1.3644e-04\n",
      "Epoch 3/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 6.4267e-05 - val_loss: 2.2219e-05\n",
      "Epoch 4/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 2.6091e-05 - val_loss: 4.3641e-05\n",
      "Epoch 5/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 1.5027e-05 - val_loss: 6.7597e-05\n",
      "Epoch 6/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.6076 - val_loss: 0.2961\n",
      "Epoch 7/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.1621 - val_loss: 3.5169e-05\n",
      "Epoch 8/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 3.6574e-06 - val_loss: 2.2025e-06\n",
      "Epoch 9/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 2.0803e-07 - val_loss: 3.3167e-08\n",
      "Epoch 10/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.2006 - val_loss: 1.3149\n",
      "Epoch 11/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.0329 - val_loss: 1.9027e-06\n",
      "Epoch 12/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 1.5598e-06 - val_loss: 2.4674e-05\n",
      "Epoch 13/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 1.8253 - val_loss: 7.5002\n",
      "Epoch 14/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.1991 - val_loss: 8.8779e-05\n",
      "Epoch 15/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 2.9133e-05 - val_loss: 1.3190e-05\n",
      "Epoch 16/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 9.7525e-07 - val_loss: 1.8899e-07\n",
      "Epoch 17/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 3.5063e-08 - val_loss: 6.2855e-09\n",
      "Epoch 18/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 2.6483e-06 - val_loss: 4.8677e-05\n",
      "Epoch 19/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 1.1690 - val_loss: 0.0048\n",
      "Epoch 20/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 1.2848e-04 - val_loss: 4.8185e-06\n",
      "Epoch 21/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 6.7313e-07 - val_loss: 1.4300e-07\n",
      "Epoch 22/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 1.3357e-07 - val_loss: 4.9837e-08\n",
      "Epoch 23/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 1.0467 - val_loss: 0.0655\n",
      "Epoch 24/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.0052 - val_loss: 5.9113e-06\n",
      "Epoch 25/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 5.9239e-07 - val_loss: 5.6067e-08\n",
      "Epoch 26/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 3.1048e-08 - val_loss: 4.1475e-08\n",
      "Epoch 27/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 4.3306e-04 - val_loss: 5.0238e-05\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_247856/837620651.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  relevant_data[\"Code Digits\"] = relevant_data[\"Code Digits\"].apply(lambda x: x + ([0] * (3-len(x))))\n",
      "/tmp/ipykernel_247856/837620651.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  relevant_data[\"Assembly Digits\"] = relevant_data[\"Assembly Digits\"].apply(lambda x: x + ([0] * (3-len(x))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 4s 10ms/step - loss: 11.5049 - val_loss: 8.9841e-05\n",
      "Epoch 2/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 4.1609e-05 - val_loss: 4.1200e-05\n",
      "Epoch 3/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 1.2706e-05 - val_loss: 4.3475e-05\n",
      "Epoch 4/100\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 0.1306 - val_loss: 4.3654e-06\n",
      "Epoch 5/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 6.2810e-07 - val_loss: 3.3084e-06\n",
      "Epoch 6/100\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 1.7731e-06 - val_loss: 5.4595e-05\n",
      "Epoch 7/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.2106 - val_loss: 0.0260\n",
      "Epoch 8/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.0094 - val_loss: 2.5436e-04\n",
      "Epoch 9/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.0297 - val_loss: 0.0325\n",
      "Epoch 10/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.1058 - val_loss: 0.0415\n",
      "Epoch 11/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.0427 - val_loss: 0.0255\n",
      "Epoch 12/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.1212 - val_loss: 1.0562e-04\n",
      "Epoch 13/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 2.1463e-05 - val_loss: 2.5555e-05\n",
      "Epoch 14/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.0681 - val_loss: 0.6512\n",
      "Epoch 15/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.6276 - val_loss: 6.2026e-05\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_247856/837620651.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  relevant_data[\"Code Digits\"] = relevant_data[\"Code Digits\"].apply(lambda x: x + ([0] * (3-len(x))))\n",
      "/tmp/ipykernel_247856/837620651.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  relevant_data[\"Assembly Digits\"] = relevant_data[\"Assembly Digits\"].apply(lambda x: x + ([0] * (3-len(x))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 5s 12ms/step - loss: 531878.8125 - val_loss: 1277522.7500\n",
      "Epoch 2/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 397920.5312 - val_loss: 1230908.7500\n",
      "Epoch 3/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 281877.7500 - val_loss: 738066.8125\n",
      "Epoch 4/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 201486.8750 - val_loss: 779818.8750\n",
      "Epoch 5/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 198340.0469 - val_loss: 670000.4375\n",
      "Epoch 6/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 199611.4688 - val_loss: 615355.1250\n",
      "Epoch 7/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 198261.4219 - val_loss: 772439.4375\n",
      "Epoch 8/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 196376.7500 - val_loss: 789560.1875\n",
      "Epoch 9/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 197436.4219 - val_loss: 768863.0625\n",
      "Epoch 10/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 196764.7812 - val_loss: 723763.9375\n",
      "Epoch 11/100\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 198300.8594 - val_loss: 808023.3125\n",
      "Epoch 12/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 199548.0156 - val_loss: 801447.5625\n",
      "Epoch 13/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 198291.1719 - val_loss: 701777.0000\n",
      "Epoch 14/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 194345.4844 - val_loss: 752582.5000\n",
      "Epoch 15/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 197781.7656 - val_loss: 630459.6250\n",
      "Epoch 16/100\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 194744.6562 - val_loss: 824200.4375\n"
     ]
    }
   ],
   "source": [
    "### OPTIMIZATION ###\n",
    "\n",
    "### Here, it generates a model per operator. These train off the data as well\n",
    "### This number is data dependent\n",
    "\n",
    "operator_models = [None] * len(operator_lookup)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "for ri in range(len(operator_lookup)):\n",
    "\n",
    "    operator_models[ri] = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(256),\n",
    "        tf.keras.layers.Dense(256),\n",
    "        tf.keras.layers.Dense(256),\n",
    "        tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "    operator_models[ri].compile(loss=\"mse\",optimizer=\"adam\")\n",
    "\n",
    "    relevant_data = data[data[\"Mapped Operator\"] == ri]\n",
    "\n",
    "    relevant_data[\"Code Digits\"] = relevant_data[\"Code Digits\"].apply(lambda x: x + ([0] * (3-len(x))))\n",
    "    relevant_data[\"Assembly Digits\"] = relevant_data[\"Assembly Digits\"].apply(lambda x: x + ([0] * (3-len(x))))\n",
    "\n",
    "    inputs = np.stack(relevant_data[\"Code Digits\"].to_numpy()).astype(int)\n",
    "    outputs = np.stack(relevant_data[\"Assembly Digits\"].to_numpy()).astype(int)\n",
    "\n",
    "    operator_models[ri].fit(x=inputs, y=outputs, validation_split=0.1, epochs=100, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_numbers(code_numbers, operator):\n",
    "    output = operator_models[operator](np.array([code_numbers]).astype(int))[0][0]\n",
    "    return round(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splice_numbers_into_assembly(template,digit):\n",
    "    return template.replace(numerical_char,str(digit.numpy().astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefixes(template):\n",
    "    lines = template.split('\\n')\n",
    "    lines = [(line.split('_')[1] if (\"_\" in line) else line) for line in lines]\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_code(code):\n",
    "    digits = re.findall(r'\\d+', code)\n",
    "    digits = digits + ([0] * (3 - len(digits)))\n",
    "\n",
    "    tokens = code.split()\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = f\"{i}_{tokens[i]}\"\n",
    "    code = \" \".join(tokens)\n",
    "\n",
    "    operator_n = classify_operator(code)\n",
    "    final_digit = compile_numbers(digits,operator_n)\n",
    "    assembly_template = generate_template(code)\n",
    "    spliced_assembly = splice_numbers_into_assembly(assembly_template, final_digit)\n",
    "    return remove_prefixes(spliced_assembly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "push rbp\n",
      "mov rbp, rsp\n",
      "mov DWORD PTR [rbp-4], edi\n",
      "mov DWORD PTR [rbp-8], esi\n",
      "mov eax, DWORD PTR [rbp-4]\n",
      "pop rbp\n",
      "ret\n",
      "⁂\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(compile_code(\"variable_a * 1\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
